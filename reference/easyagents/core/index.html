



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.6.0">
    
    
      
        <title>Core - easyagents</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/application.1b62728e.css">
      
        <link rel="stylesheet" href="../../../assets/stylesheets/application-palette.a8b3c06d.css">
      
      
        
        
        <meta name="theme-color" content="#4caf50">
      
    
    
      <script src="../../../assets/javascripts/modernizr.268332fc.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../../assets/fonts/material-icons.css">
    
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="green" data-md-color-accent="lightgreen">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#module-easyagentscore" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../.." title="easyagents" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              easyagents
            </span>
            <span class="md-header-nav__topic">
              
                Core
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/christianhidber/easyagents/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    easyagents
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../.." title="easyagents" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    easyagents
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/christianhidber/easyagents/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    easyagents
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../CODE_OF_CONDUCT/" title="Code Of Conduct" class="md-nav__link">
      Code Of Conduct
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../CONTRIBUTING/" title="Contributing" class="md-nav__link">
      Contributing
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../documentation/Markdown/Release_Notes/" title="Release Notes" class="md-nav__link">
      Release Notes
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5" checked>
    
    <label class="md-nav__link" for="nav-5">
      Reference
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Reference
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1" type="checkbox" id="nav-5-1" checked>
    
    <label class="md-nav__link" for="nav-5-1">
      Easyagents
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-1">
        Easyagents
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../agents/" title="Agents" class="md-nav__link">
      Agents
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Core
      </label>
    
    <a href="./" title="Core" class="md-nav__link md-nav__link--active">
      Core
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#agentcallback" class="md-nav__link">
    AgentCallback
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#on_api_log" class="md-nav__link">
    on_api_log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_gym_init_begin" class="md-nav__link">
    on_gym_init_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_gym_init_end" class="md-nav__link">
    on_gym_init_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_gym_reset_begin" class="md-nav__link">
    on_gym_reset_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_gym_reset_end" class="md-nav__link">
    on_gym_reset_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_gym_step_begin" class="md-nav__link">
    on_gym_step_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_gym_step_end" class="md-nav__link">
    on_gym_step_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_log" class="md-nav__link">
    on_log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_begin" class="md-nav__link">
    on_play_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_end" class="md-nav__link">
    on_play_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_step_begin" class="md-nav__link">
    on_play_step_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_step_end" class="md-nav__link">
    on_play_step_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_begin" class="md-nav__link">
    on_train_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_end" class="md-nav__link">
    on_train_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agentcontext" class="md-nav__link">
    AgentContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#instance-variables" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cemtraincontext" class="md-nav__link">
    CemTrainContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_1" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#episodestraincontext" class="md-nav__link">
    EpisodesTrainContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_2" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants_1" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_2" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gymcontext" class="md-nav__link">
    GymContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#instance-variables_3" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modelconfig" class="md-nav__link">
    ModelConfig
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#playcontext" class="md-nav__link">
    PlayContext
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plottype" class="md-nav__link">
    PlotType
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_3" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ppotraincontext" class="md-nav__link">
    PpoTrainContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_4" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_4" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyplotcontext" class="md-nav__link">
    PyPlotContext
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stepstraincontext" class="md-nav__link">
    StepsTrainContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_5" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_5" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#traincontext" class="md-nav__link">
    TrainContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#descendants_2" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_6" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../env/" title="Env" class="md-nav__link">
      Env
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1-4" type="checkbox" id="nav-5-1-4">
    
    <label class="md-nav__link" for="nav-5-1-4">
      Backends
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-1-4">
        Backends
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../backends/core/" title="Core" class="md-nav__link">
      Core
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../backends/tfagents/" title="Tfagents" class="md-nav__link">
      Tfagents
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1-5" type="checkbox" id="nav-5-1-5">
    
    <label class="md-nav__link" for="nav-5-1-5">
      Callbacks
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-1-5">
        Callbacks
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../callbacks/duration/" title="Duration" class="md-nav__link">
      Duration
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../callbacks/log/" title="Log" class="md-nav__link">
      Log
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../callbacks/plot/" title="Plot" class="md-nav__link">
      Plot
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../callbacks/save/" title="Save" class="md-nav__link">
      Save
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#agentcallback" class="md-nav__link">
    AgentCallback
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#on_api_log" class="md-nav__link">
    on_api_log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_gym_init_begin" class="md-nav__link">
    on_gym_init_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_gym_init_end" class="md-nav__link">
    on_gym_init_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_gym_reset_begin" class="md-nav__link">
    on_gym_reset_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_gym_reset_end" class="md-nav__link">
    on_gym_reset_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_gym_step_begin" class="md-nav__link">
    on_gym_step_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_gym_step_end" class="md-nav__link">
    on_gym_step_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_log" class="md-nav__link">
    on_log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_begin" class="md-nav__link">
    on_play_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_end" class="md-nav__link">
    on_play_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_step_begin" class="md-nav__link">
    on_play_step_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_step_end" class="md-nav__link">
    on_play_step_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_begin" class="md-nav__link">
    on_train_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_end" class="md-nav__link">
    on_train_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agentcontext" class="md-nav__link">
    AgentContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#instance-variables" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cemtraincontext" class="md-nav__link">
    CemTrainContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_1" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#episodestraincontext" class="md-nav__link">
    EpisodesTrainContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_2" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants_1" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_2" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gymcontext" class="md-nav__link">
    GymContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#instance-variables_3" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modelconfig" class="md-nav__link">
    ModelConfig
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#playcontext" class="md-nav__link">
    PlayContext
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plottype" class="md-nav__link">
    PlotType
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_3" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ppotraincontext" class="md-nav__link">
    PpoTrainContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_4" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_4" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyplotcontext" class="md-nav__link">
    PyPlotContext
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stepstraincontext" class="md-nav__link">
    StepsTrainContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_5" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_5" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#traincontext" class="md-nav__link">
    TrainContext
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#descendants_2" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_6" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/christianhidber/easyagents/edit/master/reference/easyagents/core.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="module-easyagentscore">Module easyagents.core</h1>
<p>This module contains the core datastructures shared between fronten and backend like the definition
of all callbacks and agent configurations.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="sd">&quot;&quot;&quot;This module contains the core datastructures shared between fronten and backend like the definition</span>

<span class="sd">    of all callbacks and agent configurations.</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Flag</span><span class="p">,</span> <span class="n">auto</span>

<span class="kn">import</span> <span class="nn">math</span>

<span class="kn">import</span> <span class="nn">easyagents.env</span>

<span class="kn">import</span> <span class="nn">easyagents.backends.monitor</span>

<span class="kn">import</span> <span class="nn">gym.core</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="k">class</span> <span class="nc">GymContext</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Contains the context for gym api calls (wrapping a gym env instance).&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_monitor_env</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">monitor</span><span class="o">.</span><span class="n">_MonitorEnv</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_totals</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">return</span> <span class="n">f</span><span class="s1">&#39;MonitorEnv={self._monitor_env} Totals={self._totals}&#39;</span>

    <span class="nd">@property</span>

    <span class="k">def</span> <span class="nf">gym_env</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Env</span><span class="p">]:</span>

        <span class="n">result</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_monitor_env</span><span class="p">:</span>

            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_monitor_env</span><span class="o">.</span><span class="n">env</span>

        <span class="k">return</span> <span class="n">result</span>

<span class="k">class</span> <span class="nc">PlotType</span><span class="p">(</span><span class="n">Flag</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Defines the point in time when a plot is created / updated.</span>

<span class="sd">    NONE: No plot is updated.</span>

<span class="sd">    PLAY_EPISODE: Called after the last step of each played episode. The gym environment is still</span>

<span class="sd">        accessible through agent_context.play-gym_env.</span>

<span class="sd">    PLAY_STEP: Called after each play step. The gym environment is still</span>

<span class="sd">        accessible through agent_context.play-gym_env.</span>

<span class="sd">    TRAIN_EVAL: Called after the last step of the last evaluation episode during training.</span>

<span class="sd">        The gym environment is accessible through agent_context.play.gym_env.</span>

<span class="sd">    TRAIN_ITERATION: Called after each train iteration. No gym environment is available.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">NONE</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">PLAY_EPISODE</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>

    <span class="n">PLAY_STEP</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>

    <span class="n">TRAIN_EVAL</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>

    <span class="n">TRAIN_ITERATION</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">PyPlotContext</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Contain the context for the maplotlib.pyplot figure plotting.</span>

<span class="sd">    Attributes</span>

<span class="sd">        figure: the figure to plot to</span>

<span class="sd">        figsize: figure (width,height) in inches for the figure to be created.</span>

<span class="sd">        is_jupyter_active: True if we plot to jupyter notebook cell, False otherwise.</span>

<span class="sd">        max_columns: the max number of subplot columns in the pyplot figure</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_created_subplots</span> <span class="o">=</span> <span class="n">PlotType</span><span class="o">.</span><span class="n">NONE</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">figure</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">figsize</span><span class="p">:</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_call_jupyter_display</span> <span class="o">=</span> <span class="bp">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">is_jupyter_active</span> <span class="o">=</span> <span class="bp">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="n">figure_number</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="n">figure_axes_len</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">figure</span><span class="p">:</span>

            <span class="n">figure_number</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">number</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">axes</span><span class="p">:</span>

                <span class="n">figure_axes_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">axes</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">f</span><span class="s1">&#39;is_jupyter_active={self.is_jupyter_active} max_columns={self.max_columns} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;_created_subplots={self._created_subplots} figure={figure_number} axes={figure_axes_len} &#39;</span>

    <span class="k">def</span> <span class="nf">_is_subplot_created</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">plot_type</span><span class="p">:</span> <span class="n">PlotType</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Yields true if a subplot of type plot_type was created by a plot callback.&quot;&quot;&quot;</span>

        <span class="n">result</span> <span class="o">=</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_created_subplots</span> <span class="o">&amp;</span> <span class="n">plot_type</span><span class="p">)</span> <span class="o">!=</span> <span class="n">PlotType</span><span class="o">.</span><span class="n">NONE</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span>

<span class="k">class</span> <span class="nc">ModelConfig</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;The model configurations, containing the name of the gym environment and the neural network architecture.</span>

<span class="sd">        Attributes:</span>

<span class="sd">            original_env_name: the name of the underlying gym environment, eg &#39;CartPole-v0&#39;</span>

<span class="sd">            gym_env_name: the name of the actual gym environment used (a wrapper around the environment given</span>

<span class="sd">                by original_env_name)</span>

<span class="sd">            fc_layers: int tuple defining the number and size of each fully connected layer.</span>

<span class="sd">            seed: the seed to be used for example for the gym_env or None for no seed</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_KEY_SEED</span> <span class="o">=</span> <span class="s1">&#39;seed&#39;</span>

    <span class="n">_KEY_GYM_ENV</span> <span class="o">=</span> <span class="s1">&#39;gym_env&#39;</span>

    <span class="n">_KEY_FC_LAYERS</span> <span class="o">=</span> <span class="s1">&#39;fc_layers&#39;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>

                 <span class="n">gym_env_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>

                 <span class="n">fc_layers</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="nb">int</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>

                 <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">            Args:</span>

<span class="sd">                gym_env_name: the name of the registered gym environment to use, eg &#39;CartPole-v0&#39;</span>

<span class="sd">                fc_layers: int tuple defining the number and size of each fully connected layer.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">fc_layers</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>

            <span class="n">fc_layers</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fc_layers</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>

            <span class="n">fc_layers</span> <span class="o">=</span> <span class="p">(</span><span class="n">fc_layers</span><span class="p">,)</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gym_env_name</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="s2">&quot;passed gym_env_name not a string.&quot;</span>

        <span class="k">assert</span> <span class="n">gym_env_name</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;gym environment name is empty.&quot;</span>

        <span class="k">assert</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">_is_registered_with_gym</span><span class="p">(</span><span class="n">gym_env_name</span><span class="p">),</span> \

            <span class="n">f</span><span class="s1">&#39;&quot;{gym_env_name}&quot; is not the name of an environment registered with OpenAI gym.&#39;</span> <span class="o">+</span> \

            <span class="s1">&#39;Consider using easyagents.env.register_with_gym to register your environment.&#39;</span>

        <span class="k">assert</span> <span class="n">fc_layers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">,</span> <span class="s2">&quot;fc_layers not set&quot;</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fc_layers</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">),</span> <span class="s2">&quot;fc_layers not a tuple&quot;</span>

        <span class="k">assert</span> <span class="n">fc_layers</span><span class="p">,</span> <span class="s2">&quot;fc_layers must contain at least 1 int&quot;</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">fc_layers</span><span class="p">:</span>

            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;{i} is not a valid size for a hidden layer&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">original_env_name</span> <span class="o">=</span> <span class="n">gym_env_name</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gym_env_name</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fc_layers</span> <span class="o">=</span> <span class="n">fc_layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">return</span> <span class="n">f</span><span class="s1">&#39;fc_layers={self.fc_layers} seed={self.seed} gym_env_name={self.gym_env_name}&#39;</span>

    <span class="nd">@staticmethod</span>

    <span class="k">def</span> <span class="nf">_from_dict</span><span class="p">(</span><span class="n">from_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">object</span><span class="p">]):</span>

        <span class="sd">&quot;&quot;&quot;Creates a new instance of ModelConfig based on the parameters contained in dict</span>

<span class="sd">        Returns:</span>

<span class="sd">            new instance of ModelConfig configured by dict</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="n">from_dict</span>

        <span class="c1"># noinspection PyTypeChecker</span>

        <span class="n">fc_layers</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">from_dict</span><span class="p">[</span><span class="n">ModelConfig</span><span class="o">.</span><span class="n">_KEY_FC_LAYERS</span><span class="p">])</span>

        <span class="c1"># noinspection PyTypeChecker</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">ModelConfig</span><span class="p">(</span><span class="n">gym_env_name</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">from_dict</span><span class="p">[</span><span class="n">ModelConfig</span><span class="o">.</span><span class="n">_KEY_GYM_ENV</span><span class="p">]),</span> <span class="n">fc_layers</span><span class="o">=</span><span class="n">fc_layers</span><span class="p">,</span>

                             <span class="n">seed</span><span class="o">=</span><span class="n">from_dict</span><span class="p">[</span><span class="n">ModelConfig</span><span class="o">.</span><span class="n">_KEY_SEED</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">_to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">object</span><span class="p">]:</span>

        <span class="sd">&quot;&quot;&quot;saves this model configuration to a dict. The model_config can be recreated by a call to _from_dict</span>

<span class="sd">        Retunns:</span>

<span class="sd">            dict containing all parameters of this model_config (this does not include any policy)</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">result</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">object</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="n">result</span><span class="p">[</span><span class="n">ModelConfig</span><span class="o">.</span><span class="n">_KEY_SEED</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span>

        <span class="n">result</span><span class="p">[</span><span class="n">ModelConfig</span><span class="o">.</span><span class="n">_KEY_GYM_ENV</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_env_name</span>

        <span class="n">result</span><span class="p">[</span><span class="n">ModelConfig</span><span class="o">.</span><span class="n">_KEY_FC_LAYERS</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_layers</span>

        <span class="k">return</span> <span class="n">result</span>

<span class="k">class</span> <span class="nc">TrainContext</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Contains the configuration of an agents train method like the number of iterations or the learning rate</span>

<span class="sd">        along with data gathered sofar during the training which is identical for all implementations.</span>

<span class="sd">        Hints:</span>

<span class="sd">        o TrainContext contains all the parameters needed to control the train loop.</span>

<span class="sd">        o Subclasses of TrainContext may contain additional Agent (but not backend) specific parameters.</span>

<span class="sd">        Attributes:</span>

<span class="sd">            num_iterations: number of times the training is repeated (with additional data), unlimited if None</span>

<span class="sd">            max_steps_per_episode: maximum number of steps per episode</span>

<span class="sd">            learning_rate: the learning rate used in the next iteration&#39;s policy training (0,1]</span>

<span class="sd">            reward_discount_gamma: the factor by which a reward is discounted for each step (0,1]</span>

<span class="sd">            max_steps_in_buffer: size of the agents buffer in steps</span>

<span class="sd">            training_done: if true the train loop is terminated at the end of the current iteration</span>

<span class="sd">            iterations_done_in_training: the number of iterations completed so far (during training)</span>

<span class="sd">            episodes_done_in_iteration: the number of episodes completed in the current iteration</span>

<span class="sd">            episodes_done_in_training: the number of episodes completed over all iterations so far.</span>

<span class="sd">                The episodes played for evaluation are not included in this count.</span>

<span class="sd">            steps_done_in_training: the number of steps taken over all iterations so far</span>

<span class="sd">            steps_done_in_iteration: the number of steps taken in the current iteration</span>

<span class="sd">            num_iterations_between_eval: number of training iterations before the current policy is evaluated.</span>

<span class="sd">            num_episodes_per_eval: number of episodes played to estimate the average return and steps</span>

<span class="sd">            eval_rewards: dict containg the rewards statistics for each policy evaluation.</span>

<span class="sd">                Each entry contains the tuple (min, average, max) over the sum of rewards over all episodes</span>

<span class="sd">                played for the current evaluation. The dict is indexed by the current_episode.</span>

<span class="sd">            eval_steps: dict containg the steps statistics for each policy evaluation.</span>

<span class="sd">                Each entry contains the tuple (min, average, max) over the number of step over all episodes</span>

<span class="sd">                played for the current evaluation. The dict is indexed by the current_episode.</span>

<span class="sd">            loss: dict containing the loss for each iteration training. The dict is indexed by the current_episode.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_iterations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_steps_per_episode</span><span class="p">:</span> <span class="n">Optional</span> <span class="o">=</span> <span class="mi">1000</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_iterations_between_eval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_episodes_per_eval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reward_discount_gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_steps_in_buffer</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100000</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">training_done</span><span class="p">:</span> <span class="nb">bool</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">iterations_done_in_training</span><span class="p">:</span> <span class="nb">int</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">episodes_done_in_iteration</span><span class="p">:</span> <span class="nb">int</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">episodes_done_in_training</span><span class="p">:</span> <span class="nb">int</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">steps_done_in_training</span><span class="p">:</span> <span class="nb">int</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">steps_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eval_rewards</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">return</span> <span class="n">f</span><span class="s1">&#39;training_done={self.training_done} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#iterations_done_in_training={self.iterations_done_in_training} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#episodes_done_in_iteration={self.episodes_done_in_iteration} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#steps_done_in_iteration={self.steps_done_in_iteration} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#iterations={self.num_iterations} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#max_steps_per_episode={self.max_steps_per_episode} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#iterations_between_eval={self.num_iterations_between_eval} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#episodes_per_eval={self.num_episodes_per_eval} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#learning_rate={self.learning_rate} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#reward_discount_gamma={self.reward_discount_gamma} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#max_steps_in_buffer={self.max_steps_in_buffer} &#39;</span>

    <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Clears all values modified during a train() call.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">training_done</span> <span class="o">=</span> <span class="bp">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">iterations_done_in_training</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">episodes_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">episodes_done_in_training</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">steps_done_in_training</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">steps_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eval_rewards</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Validates the consistency of all values, raising an exception if an inadmissible combination is detected.&quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_iterations</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_iterations</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;num_iterations not admissible&quot;</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps_per_episode</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;max_steps_per_episode not admissible&quot;</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_iterations_between_eval</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;num_iterations_between_eval not admissible&quot;</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_episodes_per_eval</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;num_episodes_per_eval not admissible&quot;</span>

        <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;learning_rate not in interval (0,1]&quot;</span>

        <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_discount_gamma</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;reward_discount_gamma not in interval (0,1]&quot;</span>

    <span class="nd">@property</span>

    <span class="k">def</span> <span class="nf">num_iterations_between_plot</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;number of iterations between 2 plot updates during training.</span>

<span class="sd">        Returns:</span>

<span class="sd">            number of iterations or 0 if no plot updates should take place.</span>

<span class="sd">            &quot;&quot;&quot;</span>

        <span class="n">result</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_iterations_between_eval</span><span class="p">:</span>

            <span class="n">result</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_iterations_between_eval</span> <span class="o">/</span> <span class="mi">3</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span>

<span class="k">class</span> <span class="nc">EpisodesTrainContext</span><span class="p">(</span><span class="n">TrainContext</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Base class for all agent which evaluate a number of episodes during each iteration:</span>

<span class="sd">        The train loop proceeds roughly as follows:</span>

<span class="sd">            for i in num_iterations</span>

<span class="sd">                for e in num_episodes_per_iterations</span>

<span class="sd">                    play episode and record steps</span>

<span class="sd">                train policy for num_epochs_per_iteration epochs</span>

<span class="sd">                if current_episode % num_iterations_between_eval == 0:</span>

<span class="sd">                    evaluate policy</span>

<span class="sd">                if training_done</span>

<span class="sd">                    break</span>

<span class="sd">        Attributes:</span>

<span class="sd">            num_episodes_per_iteration: number of episodes played per training iteration</span>

<span class="sd">            num_epochs_per_iteration: number of times the data collected for the current iteration</span>

<span class="sd">                is used to retrain the current policy</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_episodes_per_iteration</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_epochs_per_iteration</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__str__</span><span class="p">()</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#episodes_per_iteration={self.num_episodes_per_iteration} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#epochs_per_iteration={self.num_epochs_per_iteration} &#39;</span>

    <span class="k">def</span> <span class="nf">_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Validates the consistency of all values, raising an exception if an inadmissible combination is detected.&quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_episodes_per_iteration</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;num_episodes_per_iteration not admissible&quot;</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_epochs_per_iteration</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;num_epochs_per_iteration not admissible&quot;</span>

<span class="k">class</span> <span class="nc">CemTrainContext</span><span class="p">(</span><span class="n">EpisodesTrainContext</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Holds the configuration and current training state for Cross-Entropy-Methode agents.</span>

<span class="sd">        Attributes:</span>

<span class="sd">            elite_set_fraction: fraction of the elite policy set.</span>

<span class="sd">            num_steps_buffer_preload: number of steps performed to initially load the policy buffer</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">100</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_episodes_per_iteration</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">elite_set_fraction</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_steps_buffer_preload</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2000</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__str__</span><span class="p">()</span> <span class="o">+</span> <span class="n">f</span><span class="s1">&#39;#elite_set_fraction={self.elite_set_fraction} &#39;</span>

    <span class="k">def</span> <span class="nf">_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Validates the consistency of all values, raising an exception if an inadmissible combination is detected.&quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">assert</span> <span class="mi">1</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">elite_set_fraction</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;elite_set_fraction must be in interval (0,1]&quot;</span>

<span class="k">class</span> <span class="nc">PpoTrainContext</span><span class="p">(</span><span class="n">EpisodesTrainContext</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;TrainContext for Actor-Critic type agents like Ppo or Sac.</span>

<span class="sd">    Attributes:</span>

<span class="sd">        actor_loss: loss observed during training of the actor network. dict is indexed by the current_episode.</span>

<span class="sd">        critic_loss: loss observed during training of the critic network. dict is indexed by the current_episode.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">actor_loss</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">critic_loss</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">actor_loss</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">critic_loss</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">StepsTrainContext</span><span class="p">(</span><span class="n">TrainContext</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Base class for all agent which evaluate a number of steps during each iteration:</span>

<span class="sd">        The train loop proceeds roughly as follows:</span>

<span class="sd">            for i in num_iterations</span>

<span class="sd">                for s in num_steps_per_iterations</span>

<span class="sd">                    play episodes and record steps</span>

<span class="sd">                train policy for num_epochs_per_iteration epochs</span>

<span class="sd">                if current_episode % num_iterations_between_eval == 0:</span>

<span class="sd">                    evaluate policy</span>

<span class="sd">                if training_done</span>

<span class="sd">                    break</span>

<span class="sd">        Attributes:</span>

<span class="sd">            num_steps_per_iteration: number of steps played for each iteration</span>

<span class="sd">            num_steps_buffer_preload: number of initial collect steps to preload the buffer</span>

<span class="sd">            num_steps_sampled_from_buffer: the number of steps sampled from buffer for each iteration training</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">20000</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_iterations_between_eval</span> <span class="o">=</span> <span class="mi">1000</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_steps_per_iteration</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_steps_buffer_preload</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_steps_sampled_from_buffer</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_steps_in_buffer</span> <span class="o">=</span> <span class="mi">100000</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__str__</span><span class="p">()</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#steps_per_iteration={self.num_steps_per_iteration} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#steps_buffer_preload={self.num_steps_buffer_preload} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;#steps_sampled_from_buffer={self.num_steps_sampled_from_buffer} &#39;</span>

    <span class="k">def</span> <span class="nf">_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Validates the consistency of all values, raising an exception if an inadmissible combination is detected.&quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_steps_per_iteration</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;num_steps_per_iteration not admissible&quot;</span>

<span class="k">class</span> <span class="nc">PlayContext</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Contains the current configuration of an agents play method like the number of episodes to play</span>

<span class="sd">        and the max number of steps per episode.</span>

<span class="sd">        The EasyAgent.play() method proceeds (roughly) as follow:</span>

<span class="sd">        for e in num_episodes</span>

<span class="sd">            play (while steps_done_in_episode &lt; max_steps_per_episode)</span>

<span class="sd">            if playing_done</span>

<span class="sd">                break</span>

<span class="sd">        Attributes:</span>

<span class="sd">            num_episodes: number of episodes to play, unlimited if None</span>

<span class="sd">            max_steps_per_episode: maximum number of steps per episode, unlimited if None</span>

<span class="sd">            play_done: if true the play loop is terminated at the end of the current episode</span>

<span class="sd">            episodes_done: the number of episodes played (including the current episode).</span>

<span class="sd">            steps_done_in_episode: the number of steps taken in the current episode.</span>

<span class="sd">            steps_done: the number of steps played (over all episodes so far)</span>

<span class="sd">            actions: dict containing for each episode the actions taken in each step</span>

<span class="sd">            rewards: dict containing for each episode the rewards received in each step</span>

<span class="sd">            sum_of_rewards: dict containing for each episode the sum of rewards over all steps</span>

<span class="sd">            gym_env: the gym environment used to play</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TrainContext</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>

<span class="sd">             train_context: if set num_episodes, max_steps_per_episode and seed are set from train_context</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_episodes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_steps_per_episode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="k">if</span> <span class="n">train_context</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">num_episodes</span> <span class="o">=</span> <span class="n">train_context</span><span class="o">.</span><span class="n">num_episodes_per_eval</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">max_steps_per_episode</span> <span class="o">=</span> <span class="n">train_context</span><span class="o">.</span><span class="n">max_steps_per_episode</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">play_done</span><span class="p">:</span> <span class="nb">bool</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">episodes_done</span><span class="p">:</span> <span class="nb">int</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">steps_done_in_episode</span><span class="p">:</span> <span class="nb">int</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">steps_done</span><span class="p">:</span> <span class="nb">int</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">object</span><span class="p">]]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sum_of_rewards</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gym_env</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Env</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">return</span> <span class="n">f</span><span class="s1">&#39;#episodes={self.num_episodes} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;max_steps_per_episode={self.max_steps_per_episode} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;play_done={self.play_done} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;episodes_done={self.episodes_done} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;steps_done_in_episode={self.steps_done_in_episode} &#39;</span> <span class="o">+</span> \

               <span class="n">f</span><span class="s1">&#39;steps_done={self.steps_done} &#39;</span>

    <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Clears all values modified during a train() call.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">play_done</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">episodes_done</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">steps_done_in_episode</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">steps_done</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">object</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sum_of_rewards</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gym_env</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Env</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Validates the consistency of all values, raising an exception if an inadmissible combination is detected.&quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_episodes</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_episodes</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">&quot;num_episodes not admissible&quot;</span>

        <span class="k">assert</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_steps_per_episode</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps_per_episode</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> \

            <span class="s2">&quot;max_steps_per_episode not admissible&quot;</span>

<span class="k">class</span> <span class="nc">AgentContext</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Collection of state and configuration settings for a EasyAgent instance.</span>

<span class="sd">    Attributes:</span>

<span class="sd">        model: model configuration including the name of the underlying gym_environment and the</span>

<span class="sd">            policy&#39;s neural network archtitecture.</span>

<span class="sd">        train: training configuration and current train state. None if not inside a train call.</span>

<span class="sd">        play: play / eval configuration and current state. None if not inside a play call (directly or</span>

<span class="sd">            due to a evaluation inside a train loop)</span>

<span class="sd">        gym: context for gym environment related calls.</span>

<span class="sd">        pyplot: the context containing the matplotlib.pyplot figure to plot to during training or playing</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">ModelConfig</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>

<span class="sd">            model: model configuration including the name of the underlying gym_environment and the</span>

<span class="sd">                policy&#39;s neural network archtitecture.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ModelConfig</span><span class="p">),</span> <span class="s2">&quot;model not set&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">:</span> <span class="n">ModelConfig</span> <span class="o">=</span> <span class="n">model</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TrainContext</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">play</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PlayContext</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gym</span><span class="p">:</span> <span class="n">GymContext</span> <span class="o">=</span> <span class="n">GymContext</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pyplot</span><span class="p">:</span> <span class="n">PyPlotContext</span> <span class="o">=</span> <span class="n">PyPlotContext</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_is_policy_trained</span> <span class="o">=</span> <span class="bp">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_saver</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>

            <span class="n">Callable</span><span class="p">[[</span><span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">AgentCallback</span><span class="p">],</span> <span class="n">AgentCallback</span><span class="p">,</span> <span class="bp">None</span><span class="p">]],</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;agent_context:&#39;</span>

        <span class="n">result</span> <span class="o">+=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">api   =[{self.gym}]&#39;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>

            <span class="n">result</span> <span class="o">+=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">train =[{self.train}] &#39;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">play</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>

            <span class="n">result</span> <span class="o">+=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">play  =[{self.play}] &#39;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pyplot</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>

            <span class="n">result</span> <span class="o">+=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">pyplot=[{self.pyplot}] &#39;</span>

        <span class="n">result</span> <span class="o">+=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">model =[{self.model}] &#39;</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="nd">@property</span>

    <span class="k">def</span> <span class="nf">is_eval</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>

        <span class="sd">&quot;&quot;&quot;Yields true if a policy evaluation inside an agent.train(...) call is in progress.&quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">play</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">)</span>

    <span class="nd">@property</span>

    <span class="k">def</span> <span class="nf">is_play</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>

        <span class="sd">&quot;&quot;&quot;Yields true if an agent.play(...) call is in progress, but not a policy evaluation&quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">play</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_is_plot_ready</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">plot_type</span><span class="p">:</span> <span class="n">PlotType</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>

        <span class="sd">&quot;&quot;&quot;Yields true if any of the plots in plot_type is ready to be plotted.</span>

<span class="sd">        A plot_type is ready if a plot callback was registered for this type (like TRAIN_EVAL),</span>

<span class="sd">        the agent is in runtime state corresponding to the plot type (like in training and at the end of</span>

<span class="sd">        an evaluation period) and any frequency condition is met (like num_episodes_between_plot)</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">result</span> <span class="o">=</span> <span class="bp">False</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">plot_type</span> <span class="o">&amp;</span> <span class="n">PlotType</span><span class="o">.</span><span class="n">PLAY_EPISODE</span><span class="p">)</span> <span class="o">!=</span> <span class="n">PlotType</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>

            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span> <span class="o">|</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">is_play</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">pyplot</span><span class="o">.</span><span class="n">_is_subplot_created</span><span class="p">(</span><span class="n">PlotType</span><span class="o">.</span><span class="n">PLAY_EPISODE</span><span class="p">))</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">plot_type</span> <span class="o">&amp;</span> <span class="n">PlotType</span><span class="o">.</span><span class="n">PLAY_STEP</span><span class="p">)</span> <span class="o">!=</span> <span class="n">PlotType</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>

            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span> <span class="o">|</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">is_play</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">pyplot</span><span class="o">.</span><span class="n">_is_subplot_created</span><span class="p">(</span><span class="n">PlotType</span><span class="o">.</span><span class="n">PLAY_STEP</span><span class="p">))</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">plot_type</span> <span class="o">&amp;</span> <span class="n">PlotType</span><span class="o">.</span><span class="n">TRAIN_EVAL</span><span class="p">)</span> <span class="o">!=</span> <span class="n">PlotType</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>

            <span class="n">train_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_eval</span>

            <span class="n">train_result</span> <span class="o">=</span> <span class="n">train_result</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">pyplot</span><span class="o">.</span><span class="n">_is_subplot_created</span><span class="p">(</span><span class="n">PlotType</span><span class="o">.</span><span class="n">TRAIN_EVAL</span><span class="p">)</span>

            <span class="n">train_result</span> <span class="o">=</span> <span class="n">train_result</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">play</span><span class="o">.</span><span class="n">episodes_done</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_episodes_per_eval</span><span class="p">)</span>

            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span> <span class="o">|</span> <span class="n">train_result</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">plot_type</span> <span class="o">&amp;</span> <span class="n">PlotType</span><span class="o">.</span><span class="n">TRAIN_ITERATION</span><span class="p">)</span> <span class="o">!=</span> <span class="n">PlotType</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>

            <span class="n">train_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_train</span>

            <span class="n">train_result</span> <span class="o">=</span> <span class="n">train_result</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">pyplot</span><span class="o">.</span><span class="n">_is_subplot_created</span><span class="p">(</span><span class="n">PlotType</span><span class="o">.</span><span class="n">TRAIN_ITERATION</span><span class="p">)</span>

            <span class="n">train_result</span> <span class="o">=</span> <span class="n">train_result</span> <span class="ow">and</span> \

                           <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_iterations_between_plot</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> \

                           <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">iterations_done_in_training</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_iterations_between_plot</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>

            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span> <span class="o">|</span> <span class="n">train_result</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="nd">@property</span>

    <span class="k">def</span> <span class="nf">is_train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>

        <span class="sd">&quot;&quot;&quot;Yields true if an agent.train(...) call is in progress, but not a policy evaluation.&quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">play</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">AgentCallback</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Base class for all callbacks monitoring the backend algorithms api calls or the api calls to the gym</span>

<span class="sd">        environment&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_api_log</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">api_target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">log_msg</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Logs a call to the api of the agents implementation library / framework.&quot;&quot;&quot;</span>

        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">on_log</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">log_msg</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Logs a general message&quot;&quot;&quot;</span>

        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">on_gym_init_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;called when the monitored environment begins the instantiation of a new gym environment.</span>

<span class="sd">            Args:</span>

<span class="sd">                agent_context: api_context passed to calling agent</span>

<span class="sd">        &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_gym_init_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;called when the monitored environment completed the instantiation of a new gym environment.</span>

<span class="sd">        Args:</span>

<span class="sd">            agent_context: api_context passed to calling agent</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">on_gym_reset_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Before a call to gym.reset</span>

<span class="sd">            Args:</span>

<span class="sd">                agent_context: api_context passed to calling agent</span>

<span class="sd">                kwargs: the args to be passed to the underlying environment</span>

<span class="sd">        &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_gym_reset_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">reset_result</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;After a call to gym.reset was completed</span>

<span class="sd">        Args:</span>

<span class="sd">            agent_context: api_context passed to calling agent</span>

<span class="sd">            reset_result: object returned by gym.reset</span>

<span class="sd">            kwargs: args passed to gym.reset</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">on_gym_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Before a call to gym.step</span>

<span class="sd">        Args:</span>

<span class="sd">            agent_context: api_context passed to calling agent</span>

<span class="sd">            action: the action to be passed to the underlying environment</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">on_gym_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">step_result</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;After a call to gym.step was completed</span>

<span class="sd">        Args:</span>

<span class="sd">            agent_context: api_context passed to calling agent</span>

<span class="sd">            action: the action to be passed to the underlying environment</span>

<span class="sd">            step_result: (observation,reward,done,info) tuple returned by gym.step</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">on_play_episode_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called once at the start of new episode to be played (during play or eval, but not during train). &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_play_episode_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called once after an episode is done or stopped (during play or eval, but not during train).&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_play_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called once at the entry of an agent.play() call (during play or eval, but not during train). &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_play_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called once before exiting an agent.play() call (during play or eval, but not during train)&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_play_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called once before a new step is taken in the current episode (during play or eval, but not during train).</span>

<span class="sd">            Args:</span>

<span class="sd">                 agent_context: the context describing the agents current configuration</span>

<span class="sd">                 action: the action to be passed to the upcoming gym_env.step call</span>

<span class="sd">        &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_play_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">step_result</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called once after a step is completed in the current episode (during play or eval, but not during train).&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called once at the entry of an agent.train() call. &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called once before exiting an agent.train() call&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_iteration_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called once at the start of a new iteration. &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_train_iteration_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called once after the current iteration is completed&quot;&quot;&quot;</span>

<span class="k">class</span> <span class="nc">_PostProcessCallback</span><span class="p">(</span><span class="n">AgentCallback</span><span class="p">):</span>

    <span class="k">pass</span>

<span class="k">class</span> <span class="nc">_PreProcessCallback</span><span class="p">(</span><span class="n">AgentCallback</span><span class="p">):</span>

    <span class="k">pass</span>
</pre></div>


</details>
<h2 id="classes">Classes</h2>
<h3 id="agentcallback">AgentCallback</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">AgentCallback</span><span class="p">(</span>
    <span class="o">/</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>Base class for all callbacks monitoring the backend algorithms api calls or the api calls to the gym
environment</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="n">AgentCallback</span>(<span class="n">ABC</span>):

    <span class="s">&quot;&quot;&quot;Base class for all callbacks monitoring the backend algorithms api calls or the api calls to the gym</span>

<span class="s">        environment&quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">on_api_log</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>, <span class="n">api_target:</span> <span class="n">str</span>, <span class="n">log_msg:</span> <span class="n">str</span>):

        <span class="s">&quot;&quot;&quot;Logs a call to the api of the agents implementation library / framework.&quot;&quot;&quot;</span>

        <span class="nb">pass</span>

    <span class="n">def</span> <span class="n">on_log</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>, <span class="n">log_msg:</span> <span class="n">str</span>):

        <span class="s">&quot;&quot;&quot;Logs a general message&quot;&quot;&quot;</span>

        <span class="nb">pass</span>

    <span class="n">def</span> <span class="n">on_gym_init_begin</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>):

        <span class="s">&quot;&quot;&quot;called when the monitored environment begins the instantiation of a new gym environment.</span>

<span class="s">            Args:</span>

<span class="s">                agent_context: api_context passed to calling agent</span>

<span class="s">        &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">on_gym_init_end</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>):

        <span class="s">&quot;&quot;&quot;called when the monitored environment completed the instantiation of a new gym environment.</span>

<span class="s">        Args:</span>

<span class="s">            agent_context: api_context passed to calling agent</span>

<span class="s">        &quot;&quot;&quot;</span>

        <span class="nb">pass</span>

    <span class="n">def</span> <span class="n">on_gym_reset_begin</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>, **<span class="n">kwargs</span>):

        <span class="s">&quot;&quot;&quot;Before a call to gym.reset</span>

<span class="s">            Args:</span>

<span class="s">                agent_context: api_context passed to calling agent</span>

<span class="s">                kwargs: the args to be passed to the underlying environment</span>

<span class="s">        &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">on_gym_reset_end</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>, <span class="n">reset_result:</span> <span class="n">Tuple</span>, **<span class="n">kwargs</span>):

        <span class="s">&quot;&quot;&quot;After a call to gym.reset was completed</span>

<span class="s">        Args:</span>

<span class="s">            agent_context: api_context passed to calling agent</span>

<span class="s">            reset_result: object returned by gym.reset</span>

<span class="s">            kwargs: args passed to gym.reset</span>

<span class="s">        &quot;&quot;&quot;</span>

        <span class="nb">pass</span>

    <span class="n">def</span> <span class="n">on_gym_step_begin</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>, <span class="n">action</span>):

        <span class="s">&quot;&quot;&quot;Before a call to gym.step</span>

<span class="s">        Args:</span>

<span class="s">            agent_context: api_context passed to calling agent</span>

<span class="s">            action: the action to be passed to the underlying environment</span>

<span class="s">        &quot;&quot;&quot;</span>

        <span class="nb">pass</span>

    <span class="n">def</span> <span class="n">on_gym_step_end</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>, <span class="n">action</span>, <span class="n">step_result:</span> <span class="n">Tuple</span>):

        <span class="s">&quot;&quot;&quot;After a call to gym.step was completed</span>

<span class="s">        Args:</span>

<span class="s">            agent_context: api_context passed to calling agent</span>

<span class="s">            action: the action to be passed to the underlying environment</span>

<span class="s">            step_result: (observation,reward,done,info) tuple returned by gym.step</span>

<span class="s">        &quot;&quot;&quot;</span>

        <span class="nb">pass</span>

    <span class="n">def</span> <span class="n">on_play_episode_begin</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>):

        <span class="s">&quot;&quot;&quot;Called once at the start of new episode to be played (during play or eval, but not during train). &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">on_play_episode_end</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>):

        <span class="s">&quot;&quot;&quot;Called once after an episode is done or stopped (during play or eval, but not during train).&quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">on_play_begin</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>):

        <span class="s">&quot;&quot;&quot;Called once at the entry of an agent.play() call (during play or eval, but not during train). &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">on_play_end</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>):

        <span class="s">&quot;&quot;&quot;Called once before exiting an agent.play() call (during play or eval, but not during train)&quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">on_play_step_begin</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>, <span class="n">action</span>):

        <span class="s">&quot;&quot;&quot;Called once before a new step is taken in the current episode (during play or eval, but not during train).</span>

<span class="s">            Args:</span>

<span class="s">                 agent_context: the context describing the agents current configuration</span>

<span class="s">                 action: the action to be passed to the upcoming gym_env.step call</span>

<span class="s">        &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">on_play_step_end</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>, <span class="n">action</span>, <span class="n">step_result:</span> <span class="n">Tuple</span>):

        <span class="s">&quot;&quot;&quot;Called once after a step is completed in the current episode (during play or eval, but not during train).&quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">on_train_begin</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>):

        <span class="s">&quot;&quot;&quot;Called once at the entry of an agent.train() call. &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">on_train_end</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>):

        <span class="s">&quot;&quot;&quot;Called once before exiting an agent.train() call&quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">on_train_iteration_begin</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>):

        <span class="s">&quot;&quot;&quot;Called once at the start of a new iteration. &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">on_train_iteration_end</span>(<span class="k">self</span>, <span class="n">agent_context:</span> <span class="n">AgentContext</span>):

        <span class="s">&quot;&quot;&quot;Called once after the current iteration is completed&quot;&quot;&quot;</span>
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro">Ancestors (in MRO)</h4>
<ul>
<li>abc.ABC</li>
</ul>
<h4 id="descendants">Descendants</h4>
<ul>
<li>easyagents.core._PostProcessCallback</li>
<li>easyagents.core._PreProcessCallback</li>
<li>easyagents.callbacks.plot._PlotCallback</li>
<li>easyagents.callbacks.plot.Clear</li>
<li>easyagents.backends.core._BackendEvalCallback</li>
<li>easyagents.callbacks.duration.Fast</li>
<li>easyagents.callbacks.log._LogCallbackBase</li>
<li>easyagents.callbacks.log._CallbackCounts</li>
<li>easyagents.callbacks.save._SaveCallback</li>
</ul>
<h4 id="methods">Methods</h4>
<h5 id="on_api_log">on_api_log</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_api_log</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span><span class="p">,</span>
    <span class="n">api_target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span>
</pre></div>


<p>Logs a call to the api of the agents implementation library / framework.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_api_log</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">api_target</span><span class="p">:</span> <span class="n">str</span><span class="p">,</span> <span class="n">log_msg</span><span class="p">:</span> <span class="n">str</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Logs a call to the api of the agents implementation library / framework.&quot;&quot;&quot;</span>

        <span class="n">pass</span>
</pre></div>


</details>
<h5 id="on_gym_init_begin">on_gym_init_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_gym_init_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span>
<span class="p">)</span>
</pre></div>


<p>called when the monitored environment begins the instantiation of a new gym environment.</p>
<p>Args:
    agent_context: api_context passed to calling agent</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_gym_init_begin</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;called when the monitored environment begins the instantiation of a new gym environment.</span>

<span class="ss">            Args:</span>

<span class="ss">                agent_context: api_context passed to calling agent</span>

<span class="ss">        &quot;&quot;&quot;</span>
</pre></div>


</details>
<h5 id="on_gym_init_end">on_gym_init_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_gym_init_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span>
<span class="p">)</span>
</pre></div>


<p>called when the monitored environment completed the instantiation of a new gym environment.</p>
<p>Args:
    agent_context: api_context passed to calling agent</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_gym_init_end</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;called when the monitored environment completed the instantiation of a new gym environment.</span>

<span class="ss">        Args:</span>

<span class="ss">            agent_context: api_context passed to calling agent</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">pass</span>
</pre></div>


</details>
<h5 id="on_gym_reset_begin">on_gym_reset_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_gym_reset_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>Before a call to gym.reset</p>
<p>Args:
    agent_context: api_context passed to calling agent
    kwargs: the args to be passed to the underlying environment</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_gym_reset_begin</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Before a call to gym.reset</span>

<span class="ss">            Args:</span>

<span class="ss">                agent_context: api_context passed to calling agent</span>

<span class="ss">                kwargs: the args to be passed to the underlying environment</span>

<span class="ss">        &quot;&quot;&quot;</span>
</pre></div>


</details>
<h5 id="on_gym_reset_end">on_gym_reset_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_gym_reset_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span><span class="p">,</span>
    <span class="n">reset_result</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>After a call to gym.reset was completed</p>
<p>Args:
    agent_context: api_context passed to calling agent
    reset_result: object returned by gym.reset
    kwargs: args passed to gym.reset</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_gym_reset_end</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">reset_result</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;After a call to gym.reset was completed</span>

<span class="ss">        Args:</span>

<span class="ss">            agent_context: api_context passed to calling agent</span>

<span class="ss">            reset_result: object returned by gym.reset</span>

<span class="ss">            kwargs: args passed to gym.reset</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">pass</span>
</pre></div>


</details>
<h5 id="on_gym_step_begin">on_gym_step_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_gym_step_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span><span class="p">,</span>
    <span class="n">action</span>
<span class="p">)</span>
</pre></div>


<p>Before a call to gym.step</p>
<p>Args:
    agent_context: api_context passed to calling agent
    action: the action to be passed to the underlying environment</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_gym_step_begin</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Before a call to gym.step</span>

<span class="ss">        Args:</span>

<span class="ss">            agent_context: api_context passed to calling agent</span>

<span class="ss">            action: the action to be passed to the underlying environment</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">pass</span>
</pre></div>


</details>
<h5 id="on_gym_step_end">on_gym_step_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_gym_step_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span><span class="p">,</span>
    <span class="n">action</span><span class="p">,</span>
    <span class="n">step_result</span><span class="p">:</span> <span class="n">Tuple</span>
<span class="p">)</span>
</pre></div>


<p>After a call to gym.step was completed</p>
<p>Args:
    agent_context: api_context passed to calling agent
    action: the action to be passed to the underlying environment
    step_result: (observation,reward,done,info) tuple returned by gym.step</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_gym_step_end</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">step_result</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;After a call to gym.step was completed</span>

<span class="ss">        Args:</span>

<span class="ss">            agent_context: api_context passed to calling agent</span>

<span class="ss">            action: the action to be passed to the underlying environment</span>

<span class="ss">            step_result: (observation,reward,done,info) tuple returned by gym.step</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">pass</span>
</pre></div>


</details>
<h5 id="on_log">on_log</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_log</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span>
</pre></div>


<p>Logs a general message</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_log</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">log_msg</span><span class="p">:</span> <span class="n">str</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Logs a general message&quot;&quot;&quot;</span>

        <span class="n">pass</span>
</pre></div>


</details>
<h5 id="on_play_begin">on_play_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span>
<span class="p">)</span>
</pre></div>


<p>Called once at the entry of an agent.play() call (during play or eval, but not during train). </p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_play_begin</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Called once at the entry of an agent.play() call (during play or eval, but not during train). &quot;&quot;&quot;</span>
</pre></div>


</details>
<h5 id="on_play_end">on_play_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span>
<span class="p">)</span>
</pre></div>


<p>Called once before exiting an agent.play() call (during play or eval, but not during train)</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_play_end</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Called once before exiting an agent.play() call (during play or eval, but not during train)&quot;&quot;&quot;</span>
</pre></div>


</details>
<h5 id="on_play_episode_begin">on_play_episode_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span>
<span class="p">)</span>
</pre></div>


<p>Called once at the start of new episode to be played (during play or eval, but not during train). </p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_play_episode_begin</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Called once at the start of new episode to be played (during play or eval, but not during train). &quot;&quot;&quot;</span>
</pre></div>


</details>
<h5 id="on_play_episode_end">on_play_episode_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span>
<span class="p">)</span>
</pre></div>


<p>Called once after an episode is done or stopped (during play or eval, but not during train).</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_play_episode_end</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Called once after an episode is done or stopped (during play or eval, but not during train).&quot;&quot;&quot;</span>
</pre></div>


</details>
<h5 id="on_play_step_begin">on_play_step_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_step_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span><span class="p">,</span>
    <span class="n">action</span>
<span class="p">)</span>
</pre></div>


<p>Called once before a new step is taken in the current episode (during play or eval, but not during train).</p>
<p>Args:
     agent_context: the context describing the agents current configuration
     action: the action to be passed to the upcoming gym_env.step call</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_play_step_begin</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Called once before a new step is taken in the current episode (during play or eval, but not during train).</span>

<span class="ss">            Args:</span>

<span class="ss">                 agent_context: the context describing the agents current configuration</span>

<span class="ss">                 action: the action to be passed to the upcoming gym_env.step call</span>

<span class="ss">        &quot;&quot;&quot;</span>
</pre></div>


</details>
<h5 id="on_play_step_end">on_play_step_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_step_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span><span class="p">,</span>
    <span class="n">action</span><span class="p">,</span>
    <span class="n">step_result</span><span class="p">:</span> <span class="n">Tuple</span>
<span class="p">)</span>
</pre></div>


<p>Called once after a step is completed in the current episode (during play or eval, but not during train).</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_play_step_end</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">step_result</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Called once after a step is completed in the current episode (during play or eval, but not during train).&quot;&quot;&quot;</span>
</pre></div>


</details>
<h5 id="on_train_begin">on_train_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span>
<span class="p">)</span>
</pre></div>


<p>Called once at the entry of an agent.train() call. </p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_train_begin</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Called once at the entry of an agent.train() call. &quot;&quot;&quot;</span>
</pre></div>


</details>
<h5 id="on_train_end">on_train_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span>
<span class="p">)</span>
</pre></div>


<p>Called once before exiting an agent.train() call</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_train_end</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Called once before exiting an agent.train() call&quot;&quot;&quot;</span>
</pre></div>


</details>
<h5 id="on_train_iteration_begin">on_train_iteration_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span>
<span class="p">)</span>
</pre></div>


<p>Called once at the start of a new iteration. </p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_train_iteration_begin</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Called once at the start of a new iteration. &quot;&quot;&quot;</span>
</pre></div>


</details>
<h5 id="on_train_iteration_end">on_train_iteration_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">agent_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span>
<span class="p">)</span>
</pre></div>


<p>Called once after the current iteration is completed</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_train_iteration_end</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">AgentContext</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Called once after the current iteration is completed&quot;&quot;&quot;</span>
</pre></div>


</details>
<h3 id="agentcontext">AgentContext</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">AgentContext</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span>
<span class="p">)</span>
</pre></div>


<p>Collection of state and configuration settings for a EasyAgent instance.</p>
<p>Attributes:
    model: model configuration including the name of the underlying gym_environment and the
        policy's neural network archtitecture.
    train: training configuration and current train state. None if not inside a train call.
    play: play / eval configuration and current state. None if not inside a play call (directly or
        due to a evaluation inside a train loop)
    gym: context for gym environment related calls.
    pyplot: the context containing the matplotlib.pyplot figure to plot to during training or playing</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="n">AgentContext</span><span class="p">(</span><span class="k">object</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Collection of state and configuration settings for a EasyAgent instance.</span>

<span class="ss">    Attributes:</span>

<span class="ss">        model: model configuration including the name of the underlying gym_environment and the</span>

<span class="ss">            policy&#39;s neural network archtitecture.</span>

<span class="ss">        train: training configuration and current train state. None if not inside a train call.</span>

<span class="ss">        play: play / eval configuration and current state. None if not inside a play call (directly or</span>

<span class="ss">            due to a evaluation inside a train loop)</span>

<span class="ss">        gym: context for gym environment related calls.</span>

<span class="ss">        pyplot: the context containing the matplotlib.pyplot figure to plot to during training or playing</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">model</span><span class="p">:</span><span class="w"> </span><span class="n">ModelConfig</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;</span>

<span class="ss">        Args:</span>

<span class="ss">            model: model configuration including the name of the underlying gym_environment and the</span>

<span class="ss">                policy&#39;s neural network archtitecture.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">ModelConfig</span><span class="p">),</span><span class="w"> </span><span class="ss">&quot;model not set&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">model</span><span class="p">:</span><span class="w"> </span><span class="n">ModelConfig</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">train</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">TrainContext</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">play</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">PlayContext</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">gym</span><span class="p">:</span><span class="w"> </span><span class="n">GymContext</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GymContext</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">pyplot</span><span class="p">:</span><span class="w"> </span><span class="n">PyPlotContext</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">PyPlotContext</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_is_policy_trained</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">False</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">_agent_saver</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n"></span>

<span class="n">            Callable[[Optional[str</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="ow">Union</span><span class="o">[</span><span class="n">List[AgentCallback</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">AgentCallback</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="err">]]</span><span class="p">,</span><span class="w"> </span><span class="nf">str</span><span class="err">]]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__str__</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="s1">&#39;agent_context:&#39;</span><span class="w"></span>

<span class="w">        </span><span class="k">result</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">f</span><span class="s1">&#39;\napi   =[{self.gym}]&#39;</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="k">result</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">f</span><span class="s1">&#39;\ntrain =[{self.train}] &#39;</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">play</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="k">result</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">f</span><span class="s1">&#39;\nplay  =[{self.play}] &#39;</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">pyplot</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="k">result</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">f</span><span class="s1">&#39;\npyplot=[{self.pyplot}] &#39;</span><span class="w"></span>

<span class="w">        </span><span class="k">result</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">f</span><span class="s1">&#39;\nmodel =[{self.model}] &#39;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">result</span><span class="w"></span>

<span class="w">    </span><span class="nv">@property</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">is_eval</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nl">bool</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Yields true if a policy evaluation inside an agent.train(...) call is in progress.&quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">play</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="nv">@property</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">is_play</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nl">bool</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Yields true if an agent.play(...) call is in progress, but not a policy evaluation&quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">play</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">_is_plot_ready</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">plot_type</span><span class="p">:</span><span class="w"> </span><span class="n">PlotType</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nl">bool</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Yields true if any of the plots in plot_type is ready to be plotted.</span>

<span class="ss">        A plot_type is ready if a plot callback was registered for this type (like TRAIN_EVAL),</span>

<span class="ss">        the agent is in runtime state corresponding to the plot type (like in training and at the end of</span>

<span class="ss">        an evaluation period) and any frequency condition is met (like num_episodes_between_plot)</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">False</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">plot_type</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">PlotType</span><span class="p">.</span><span class="n">PLAY_EPISODE</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">PlotType</span><span class="p">.</span><span class="k">NONE</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">result</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">is_play</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">_is_subplot_created</span><span class="p">(</span><span class="n">PlotType</span><span class="p">.</span><span class="n">PLAY_EPISODE</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">plot_type</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">PlotType</span><span class="p">.</span><span class="n">PLAY_STEP</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">PlotType</span><span class="p">.</span><span class="k">NONE</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">result</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">is_play</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">_is_subplot_created</span><span class="p">(</span><span class="n">PlotType</span><span class="p">.</span><span class="n">PLAY_STEP</span><span class="p">))</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">plot_type</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">PlotType</span><span class="p">.</span><span class="n">TRAIN_EVAL</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">PlotType</span><span class="p">.</span><span class="k">NONE</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="n">train_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">is_eval</span><span class="w"></span>

<span class="w">            </span><span class="n">train_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_result</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">_is_subplot_created</span><span class="p">(</span><span class="n">PlotType</span><span class="p">.</span><span class="n">TRAIN_EVAL</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">train_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_result</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">play</span><span class="p">.</span><span class="n">episodes_done</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">num_episodes_per_eval</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">result</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">train_result</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">plot_type</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">PlotType</span><span class="p">.</span><span class="n">TRAIN_ITERATION</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">PlotType</span><span class="p">.</span><span class="k">NONE</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="n">train_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">is_train</span><span class="w"></span>

<span class="w">            </span><span class="n">train_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_result</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">_is_subplot_created</span><span class="p">(</span><span class="n">PlotType</span><span class="p">.</span><span class="n">TRAIN_ITERATION</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">train_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_result</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">                           </span><span class="n">self</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">num_iterations_between_plot</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">                           </span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">iterations_done_in_training</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">num_iterations_between_plot</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">result</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">train_result</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">result</span><span class="w"></span>

<span class="w">    </span><span class="nv">@property</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">is_train</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nl">bool</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Yields true if an agent.train(...) call is in progress, but not a policy evaluation.&quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">play</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"></span>
</pre></div>


</details>
<hr />
<h4 id="instance-variables">Instance variables</h4>
<div class="codehilite"><pre><span></span><span class="n">is_eval</span>
</pre></div>


<p>Yields true if a policy evaluation inside an agent.train(...) call is in progress.</p>
<div class="codehilite"><pre><span></span><span class="n">is_play</span>
</pre></div>


<p>Yields true if an agent.play(...) call is in progress, but not a policy evaluation</p>
<div class="codehilite"><pre><span></span><span class="n">is_train</span>
</pre></div>


<p>Yields true if an agent.train(...) call is in progress, but not a policy evaluation.</p>
<h3 id="cemtraincontext">CemTrainContext</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">CemTrainContext</span><span class="p">(</span>

<span class="p">)</span>
</pre></div>


<p>Holds the configuration and current training state for Cross-Entropy-Methode agents.</p>
<p>Attributes:
    elite_set_fraction: fraction of the elite policy set.
    num_steps_buffer_preload: number of steps performed to initially load the policy buffer</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="n">CemTrainContext</span>(<span class="n">EpisodesTrainContext</span>):

    <span class="s">&quot;&quot;&quot;Holds the configuration and current training state for Cross-Entropy-Methode agents.</span>

<span class="s">        Attributes:</span>

<span class="s">            elite_set_fraction: fraction of the elite policy set.</span>

<span class="s">            num_steps_buffer_preload: number of steps performed to initially load the policy buffer</span>

<span class="s">    &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">__init__</span>(<span class="k">self</span>):

        <span class="n">super</span>().<span class="n">__init__</span>()

        <span class="k">self</span>.<span class="n">num_iterations</span> = <span class="mi">100</span>

        <span class="k">self</span>.<span class="n">num_episodes_per_iteration:</span> <span class="nb">int</span> = <span class="mi">50</span>

        <span class="k">self</span>.<span class="n">elite_set_fraction:</span> <span class="n">float</span> = <span class="mf">0.1</span>

        <span class="k">self</span>.<span class="n">num_steps_buffer_preload:</span> <span class="nb">int</span> = <span class="mi">2000</span>

    <span class="n">def</span> <span class="n">__str__</span>(<span class="k">self</span>):

        <span class="k">return</span> <span class="n">super</span>().<span class="n">__str__</span>() + <span class="n">f&#39;</span><span class="c1">#elite_set_fraction={self.elite_set_fraction} &#39;</span>

    <span class="n">def</span> <span class="n">_validate</span>(<span class="k">self</span>):

        <span class="s">&quot;&quot;&quot;Validates the consistency of all values, raising an exception if an inadmissible combination is detected.&quot;&quot;&quot;</span>

        <span class="n">super</span>().<span class="n">_validate</span>()

        <span class="n">assert</span> <span class="mi">1</span> &gt;= <span class="k">self</span>.<span class="n">elite_set_fraction</span> &gt; <span class="mi">0</span>, <span class="s">&quot;elite_set_fraction must be in interval (0,1]&quot;</span>
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro_1">Ancestors (in MRO)</h4>
<ul>
<li>easyagents.core.EpisodesTrainContext</li>
<li>easyagents.core.TrainContext</li>
</ul>
<h4 id="instance-variables_1">Instance variables</h4>
<div class="codehilite"><pre><span></span><span class="n">num_iterations_between_plot</span>
</pre></div>


<p>number of iterations between 2 plot updates during training.</p>
<p>Returns:
    number of iterations or 0 if no plot updates should take place.</p>
<h3 id="episodestraincontext">EpisodesTrainContext</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">EpisodesTrainContext</span><span class="p">(</span>

<span class="p">)</span>
</pre></div>


<p>Base class for all agent which evaluate a number of episodes during each iteration:</p>
<p>The train loop proceeds roughly as follows:
    for i in num_iterations
        for e in num_episodes_per_iterations
            play episode and record steps
        train policy for num_epochs_per_iteration epochs
        if current_episode % num_iterations_between_eval == 0:
            evaluate policy
        if training_done
            break</p>
<p>Attributes:
    num_episodes_per_iteration: number of episodes played per training iteration
    num_epochs_per_iteration: number of times the data collected for the current iteration
        is used to retrain the current policy</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="n">EpisodesTrainContext</span>(<span class="n">TrainContext</span>):

    <span class="s">&quot;&quot;&quot;Base class for all agent which evaluate a number of episodes during each iteration:</span>

<span class="s">        The train loop proceeds roughly as follows:</span>

<span class="s">            for i in num_iterations</span>

<span class="s">                for e in num_episodes_per_iterations</span>

<span class="s">                    play episode and record steps</span>

<span class="s">                train policy for num_epochs_per_iteration epochs</span>

<span class="s">                if current_episode % num_iterations_between_eval == 0:</span>

<span class="s">                    evaluate policy</span>

<span class="s">                if training_done</span>

<span class="s">                    break</span>

<span class="s">        Attributes:</span>

<span class="s">            num_episodes_per_iteration: number of episodes played per training iteration</span>

<span class="s">            num_epochs_per_iteration: number of times the data collected for the current iteration</span>

<span class="s">                is used to retrain the current policy</span>

<span class="s">    &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">__init__</span>(<span class="k">self</span>):

        <span class="k">self</span>.<span class="n">num_episodes_per_iteration:</span> <span class="nb">int</span> = <span class="mi">10</span>

        <span class="k">self</span>.<span class="n">num_epochs_per_iteration:</span> <span class="nb">int</span> = <span class="mi">10</span>

        <span class="n">super</span>().<span class="n">__init__</span>()

    <span class="n">def</span> <span class="n">__str__</span>(<span class="k">self</span>):

        <span class="k">return</span> <span class="n">super</span>().<span class="n">__str__</span>() + \

               <span class="n">f&#39;</span><span class="c1">#episodes_per_iteration={self.num_episodes_per_iteration} &#39; + \</span>

               <span class="n">f&#39;</span><span class="c1">#epochs_per_iteration={self.num_epochs_per_iteration} &#39;</span>

    <span class="n">def</span> <span class="n">_validate</span>(<span class="k">self</span>):

        <span class="s">&quot;&quot;&quot;Validates the consistency of all values, raising an exception if an inadmissible combination is detected.&quot;&quot;&quot;</span>

        <span class="n">super</span>().<span class="n">_validate</span>()

        <span class="n">assert</span> <span class="k">self</span>.<span class="n">num_episodes_per_iteration</span> &gt; <span class="mi">0</span>, <span class="s">&quot;num_episodes_per_iteration not admissible&quot;</span>

        <span class="n">assert</span> <span class="k">self</span>.<span class="n">num_epochs_per_iteration</span> &gt; <span class="mi">0</span>, <span class="s">&quot;num_epochs_per_iteration not admissible&quot;</span>
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro_2">Ancestors (in MRO)</h4>
<ul>
<li>easyagents.core.TrainContext</li>
</ul>
<h4 id="descendants_1">Descendants</h4>
<ul>
<li>easyagents.core.CemTrainContext</li>
<li>easyagents.core.PpoTrainContext</li>
</ul>
<h4 id="instance-variables_2">Instance variables</h4>
<div class="codehilite"><pre><span></span><span class="n">num_iterations_between_plot</span>
</pre></div>


<p>number of iterations between 2 plot updates during training.</p>
<p>Returns:
    number of iterations or 0 if no plot updates should take place.</p>
<h3 id="gymcontext">GymContext</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">GymContext</span><span class="p">(</span>

<span class="p">)</span>
</pre></div>


<p>Contains the context for gym api calls (wrapping a gym env instance).</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="n">GymContext</span><span class="p">(</span><span class="k">object</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Contains the context for gym api calls (wrapping a gym env instance).&quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">_monitor_env</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">easyagents.backends.monitor._MonitorEnv</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_totals</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__str__</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">f</span><span class="s1">&#39;MonitorEnv={self._monitor_env} Totals={self._totals}&#39;</span><span class="w"></span>

<span class="w">    </span><span class="nv">@property</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">gym_env</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">gym.core.Env</span><span class="o">]</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">_monitor_env</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_monitor_env</span><span class="p">.</span><span class="n">env</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">result</span><span class="w"></span>
</pre></div>


</details>
<hr />
<h4 id="instance-variables_3">Instance variables</h4>
<div class="codehilite"><pre><span></span><span class="n">gym_env</span>
</pre></div>


<h3 id="modelconfig">ModelConfig</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">ModelConfig</span><span class="p">(</span>
    <span class="n">gym_env_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">fc_layers</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="nb">int</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>The model configurations, containing the name of the gym environment and the neural network architecture.</p>
<p>Attributes:
    original_env_name: the name of the underlying gym environment, eg 'CartPole-v0'
    gym_env_name: the name of the actual gym environment used (a wrapper around the environment given
        by original_env_name)
    fc_layers: int tuple defining the number and size of each fully connected layer.
    seed: the seed to be used for example for the gym_env or None for no seed</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="n">ModelConfig</span><span class="p">(</span><span class="k">object</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;The model configurations, containing the name of the gym environment and the neural network architecture.</span>

<span class="ss">        Attributes:</span>

<span class="ss">            original_env_name: the name of the underlying gym environment, eg &#39;CartPole-v0&#39;</span>

<span class="ss">            gym_env_name: the name of the actual gym environment used (a wrapper around the environment given</span>

<span class="ss">                by original_env_name)</span>

<span class="ss">            fc_layers: int tuple defining the number and size of each fully connected layer.</span>

<span class="ss">            seed: the seed to be used for example for the gym_env or None for no seed</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">_KEY_SEED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;seed&#39;</span><span class="w"></span>

<span class="w">    </span><span class="n">_KEY_GYM_ENV</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;gym_env&#39;</span><span class="w"></span>

<span class="w">    </span><span class="n">_KEY_FC_LAYERS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;fc_layers&#39;</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">                 </span><span class="nl">gym_env_name</span><span class="p">:</span><span class="w"> </span><span class="nf">str</span><span class="p">,</span><span class="w"></span>

<span class="w">                 </span><span class="nl">fc_layers</span><span class="p">:</span><span class="w"> </span><span class="ow">Union</span><span class="o">[</span><span class="n">Tuple[int, ...</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="nc">int</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="p">,</span><span class="w"></span>

<span class="w">                 </span><span class="nl">seed</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">int</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;</span>

<span class="ss">            Args:</span>

<span class="ss">                gym_env_name: the name of the registered gym environment to use, eg &#39;CartPole-v0&#39;</span>

<span class="ss">                fc_layers: int tuple defining the number and size of each fully connected layer.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">fc_layers</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="n">fc_layers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="mi">100</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">fc_layers</span><span class="p">,</span><span class="w"> </span><span class="nc">int</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="n">fc_layers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">fc_layers</span><span class="p">,)</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">gym_env_name</span><span class="p">,</span><span class="w"> </span><span class="nf">str</span><span class="p">),</span><span class="w"> </span><span class="ss">&quot;passed gym_env_name not a string.&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="n">gym_env_name</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="ss">&quot;&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;gym environment name is empty.&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="n">easyagents</span><span class="p">.</span><span class="n">env</span><span class="p">.</span><span class="n">_is_registered_with_gym</span><span class="p">(</span><span class="n">gym_env_name</span><span class="p">),</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">            </span><span class="n">f</span><span class="s1">&#39;&quot;{gym_env_name}&quot; is not the name of an environment registered with OpenAI gym.&#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">            </span><span class="s1">&#39;Consider using easyagents.env.register_with_gym to register your environment.&#39;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="n">fc_layers</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;fc_layers not set&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">fc_layers</span><span class="p">,</span><span class="w"> </span><span class="n">tuple</span><span class="p">),</span><span class="w"> </span><span class="ss">&quot;fc_layers not a tuple&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="n">fc_layers</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;fc_layers must contain at least 1 int&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nl">fc_layers</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="n">assert</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="nc">int</span><span class="p">)</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">f</span><span class="s1">&#39;{i} is not a valid size for a hidden layer&#39;</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">original_env_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gym_env_name</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">gym_env_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">fc_layers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fc_layers</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">seed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">seed</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__str__</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">f</span><span class="s1">&#39;fc_layers={self.fc_layers} seed={self.seed} gym_env_name={self.gym_env_name}&#39;</span><span class="w"></span>

<span class="w">    </span><span class="nv">@staticmethod</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">_from_dict</span><span class="p">(</span><span class="nl">from_dict</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, object</span><span class="o">]</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Creates a new instance of ModelConfig based on the parameters contained in dict</span>

<span class="ss">        Returns:</span>

<span class="ss">            new instance of ModelConfig configured by dict</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="n">from_dict</span><span class="w"></span>

<span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="n">noinspection</span><span class="w"> </span><span class="n">PyTypeChecker</span><span class="w"></span>

<span class="w">        </span><span class="n">fc_layers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tuple</span><span class="p">(</span><span class="n">from_dict</span><span class="o">[</span><span class="n">ModelConfig._KEY_FC_LAYERS</span><span class="o">]</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="n">noinspection</span><span class="w"> </span><span class="n">PyTypeChecker</span><span class="w"></span>

<span class="w">        </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ModelConfig</span><span class="p">(</span><span class="n">gym_env_name</span><span class="o">=</span><span class="nf">str</span><span class="p">(</span><span class="n">from_dict</span><span class="o">[</span><span class="n">ModelConfig._KEY_GYM_ENV</span><span class="o">]</span><span class="p">),</span><span class="w"> </span><span class="n">fc_layers</span><span class="o">=</span><span class="n">fc_layers</span><span class="p">,</span><span class="w"></span>

<span class="w">                             </span><span class="n">seed</span><span class="o">=</span><span class="n">from_dict</span><span class="o">[</span><span class="n">ModelConfig._KEY_SEED</span><span class="o">]</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">result</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">_to_dict</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, object</span><span class="o">]</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;saves this model configuration to a dict. The model_config can be recreated by a call to _from_dict</span>

<span class="ss">        Retunns:</span>

<span class="ss">            dict containing all parameters of this model_config (this does not include any policy)</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">result</span><span class="err">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, object</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dict</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="k">result</span><span class="o">[</span><span class="n">ModelConfig._KEY_SEED</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">seed</span><span class="w"></span>

<span class="w">        </span><span class="k">result</span><span class="o">[</span><span class="n">ModelConfig._KEY_GYM_ENV</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">original_env_name</span><span class="w"></span>

<span class="w">        </span><span class="k">result</span><span class="o">[</span><span class="n">ModelConfig._KEY_FC_LAYERS</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">fc_layers</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">result</span><span class="w"></span>
</pre></div>


</details>
<hr />
<h3 id="playcontext">PlayContext</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">PlayContext</span><span class="p">(</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>Contains the current configuration of an agents play method like the number of episodes to play
and the max number of steps per episode.</p>
<p>The EasyAgent.play() method proceeds (roughly) as follow:</p>
<p>for e in num_episodes
    play (while steps_done_in_episode &lt; max_steps_per_episode)
    if playing_done
        break</p>
<p>Attributes:
    num_episodes: number of episodes to play, unlimited if None
    max_steps_per_episode: maximum number of steps per episode, unlimited if None
    play_done: if true the play loop is terminated at the end of the current episode
    episodes_done: the number of episodes played (including the current episode).
    steps_done_in_episode: the number of steps taken in the current episode.
    steps_done: the number of steps played (over all episodes so far)</p>
<div class="codehilite"><pre><span></span><span class="n">actions</span><span class="o">:</span> <span class="n">dict</span> <span class="n">containing</span> <span class="k">for</span> <span class="k">each</span> <span class="n">episode</span> <span class="n">the</span> <span class="n">actions</span> <span class="n">taken</span> <span class="k">in</span> <span class="k">each</span> <span class="n">step</span>
<span class="n">rewards</span><span class="o">:</span> <span class="n">dict</span> <span class="n">containing</span> <span class="k">for</span> <span class="k">each</span> <span class="n">episode</span> <span class="n">the</span> <span class="n">rewards</span> <span class="n">received</span> <span class="k">in</span> <span class="k">each</span> <span class="n">step</span>
<span class="n">sum_of_rewards</span><span class="o">:</span> <span class="n">dict</span> <span class="n">containing</span> <span class="k">for</span> <span class="k">each</span> <span class="n">episode</span> <span class="n">the</span> <span class="n">sum</span> <span class="n">of</span> <span class="n">rewards</span> <span class="n">over</span> <span class="n">all</span> <span class="n">steps</span>
<span class="n">gym_env</span><span class="o">:</span> <span class="n">the</span> <span class="n">gym</span> <span class="n">environment</span> <span class="n">used</span> <span class="n">to</span> <span class="n">play</span>
</pre></div>


<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="n">PlayContext</span><span class="p">(</span><span class="k">object</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Contains the current configuration of an agents play method like the number of episodes to play</span>

<span class="ss">        and the max number of steps per episode.</span>

<span class="ss">        The EasyAgent.play() method proceeds (roughly) as follow:</span>

<span class="ss">        for e in num_episodes</span>

<span class="ss">            play (while steps_done_in_episode &lt; max_steps_per_episode)</span>

<span class="ss">            if playing_done</span>

<span class="ss">                break</span>

<span class="ss">        Attributes:</span>

<span class="ss">            num_episodes: number of episodes to play, unlimited if None</span>

<span class="ss">            max_steps_per_episode: maximum number of steps per episode, unlimited if None</span>

<span class="ss">            play_done: if true the play loop is terminated at the end of the current episode</span>

<span class="ss">            episodes_done: the number of episodes played (including the current episode).</span>

<span class="ss">            steps_done_in_episode: the number of steps taken in the current episode.</span>

<span class="ss">            steps_done: the number of steps played (over all episodes so far)</span>

<span class="ss">            actions: dict containing for each episode the actions taken in each step</span>

<span class="ss">            rewards: dict containing for each episode the rewards received in each step</span>

<span class="ss">            sum_of_rewards: dict containing for each episode the sum of rewards over all steps</span>

<span class="ss">            gym_env: the gym environment used to play</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">train_context</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">TrainContext</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;</span>

<span class="ss">        Args:</span>

<span class="ss">             train_context: if set num_episodes, max_steps_per_episode and seed are set from train_context</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">num_episodes</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">int</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">max_steps_per_episode</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">int</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">train_context</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">num_episodes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_context</span><span class="p">.</span><span class="n">num_episodes_per_eval</span><span class="w"></span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">max_steps_per_episode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_context</span><span class="p">.</span><span class="n">max_steps_per_episode</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">play_done</span><span class="p">:</span><span class="w"> </span><span class="n">bool</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">episodes_done</span><span class="p">:</span><span class="w"> </span><span class="nc">int</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">steps_done_in_episode</span><span class="p">:</span><span class="w"> </span><span class="nc">int</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">steps_done</span><span class="p">:</span><span class="w"> </span><span class="nc">int</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">actions</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">int, List[object</span><span class="o">]</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">rewards</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">int, List[float</span><span class="o">]</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">sum_of_rewards</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">int, float</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">gym_env</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">gym.core.Env</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__str__</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">f</span><span class="s1">&#39;#episodes={self.num_episodes} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;max_steps_per_episode={self.max_steps_per_episode} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;play_done={self.play_done} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;episodes_done={self.episodes_done} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;steps_done_in_episode={self.steps_done_in_episode} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;steps_done={self.steps_done} &#39;</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">_reset</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Clears all values modified during a train() call.&quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">play_done</span><span class="p">:</span><span class="w"> </span><span class="n">bool</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">False</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">episodes_done</span><span class="p">:</span><span class="w"> </span><span class="nc">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">steps_done_in_episode</span><span class="p">:</span><span class="w"> </span><span class="nc">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">steps_done</span><span class="p">:</span><span class="w"> </span><span class="nc">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">actions</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">int, List[object</span><span class="o">]</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dict</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">rewards</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">int, List[float</span><span class="o">]</span><span class="err">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dict</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">sum_of_rewards</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">int, float</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dict</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">gym_env</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">gym.core.Env</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">_validate</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Validates the consistency of all values, raising an exception if an inadmissible combination is detected.&quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_episodes</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_episodes</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">),</span><span class="w"> </span><span class="ss">&quot;num_episodes not admissible&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">max_steps_per_episode</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">max_steps_per_episode</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">            </span><span class="ss">&quot;max_steps_per_episode not admissible&quot;</span><span class="w"></span>
</pre></div>


</details>
<hr />
<h3 id="plottype">PlotType</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">PlotType</span><span class="p">(</span>
    <span class="o">/</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>Defines the point in time when a plot is created / updated.</p>
<p>NONE: No plot is updated.
PLAY_EPISODE: Called after the last step of each played episode. The gym environment is still
    accessible through agent_context.play-gym_env.
PLAY_STEP: Called after each play step. The gym environment is still
    accessible through agent_context.play-gym_env.
TRAIN_EVAL: Called after the last step of the last evaluation episode during training.
    The gym environment is accessible through agent_context.play.gym_env.
TRAIN_ITERATION: Called after each train iteration. No gym environment is available.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="n">PlotType</span>(<span class="n">Flag</span>):

    <span class="s">&quot;&quot;&quot;Defines the point in time when a plot is created / updated.</span>

<span class="s">    NONE: No plot is updated.</span>

<span class="s">    PLAY_EPISODE: Called after the last step of each played episode. The gym environment is still</span>

<span class="s">        accessible through agent_context.play-gym_env.</span>

<span class="s">    PLAY_STEP: Called after each play step. The gym environment is still</span>

<span class="s">        accessible through agent_context.play-gym_env.</span>

<span class="s">    TRAIN_EVAL: Called after the last step of the last evaluation episode during training.</span>

<span class="s">        The gym environment is accessible through agent_context.play.gym_env.</span>

<span class="s">    TRAIN_ITERATION: Called after each train iteration. No gym environment is available.</span>

<span class="s">    &quot;&quot;&quot;</span>

    <span class="n">NONE</span> = <span class="mi">0</span>

    <span class="n">PLAY_EPISODE</span> = <span class="n">auto</span>()

    <span class="n">PLAY_STEP</span> = <span class="n">auto</span>()

    <span class="n">TRAIN_EVAL</span> = <span class="n">auto</span>()

    <span class="n">TRAIN_ITERATION</span> = <span class="n">auto</span>()
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro_3">Ancestors (in MRO)</h4>
<ul>
<li>enum.Flag</li>
<li>enum.Enum</li>
</ul>
<h4 id="class-variables">Class variables</h4>
<div class="codehilite"><pre><span></span><span class="n">NONE</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">PLAY_EPISODE</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">PLAY_STEP</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">TRAIN_EVAL</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">TRAIN_ITERATION</span>
</pre></div>


<h3 id="ppotraincontext">PpoTrainContext</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">PpoTrainContext</span><span class="p">(</span>

<span class="p">)</span>
</pre></div>


<p>TrainContext for Actor-Critic type agents like Ppo or Sac.</p>
<p>Attributes:
    actor_loss: loss observed during training of the actor network. dict is indexed by the current_episode.
    critic_loss: loss observed during training of the critic network. dict is indexed by the current_episode.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="n">PpoTrainContext</span>(<span class="n">EpisodesTrainContext</span>):

    <span class="s">&quot;&quot;&quot;TrainContext for Actor-Critic type agents like Ppo or Sac.</span>

<span class="s">    Attributes:</span>

<span class="s">        actor_loss: loss observed during training of the actor network. dict is indexed by the current_episode.</span>

<span class="s">        critic_loss: loss observed during training of the critic network. dict is indexed by the current_episode.</span>

<span class="s">    &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">__init__</span>(<span class="k">self</span>):

        <span class="n">super</span>().<span class="n">__init__</span>()

        <span class="k">self</span>.<span class="n">actor_loss:</span> <span class="n">Dict</span>[<span class="nb">int</span>, <span class="n">float</span>]

        <span class="k">self</span>.<span class="n">critic_loss:</span> <span class="n">Dict</span>[<span class="nb">int</span>, <span class="n">float</span>]

    <span class="n">def</span> <span class="n">_reset</span>(<span class="k">self</span>):

        <span class="k">self</span>.<span class="n">actor_loss</span> = <span class="n">dict</span>()

        <span class="k">self</span>.<span class="n">critic_loss</span> = <span class="n">dict</span>()

        <span class="n">super</span>().<span class="n">_reset</span>()
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro_4">Ancestors (in MRO)</h4>
<ul>
<li>easyagents.core.EpisodesTrainContext</li>
<li>easyagents.core.TrainContext</li>
</ul>
<h4 id="instance-variables_4">Instance variables</h4>
<div class="codehilite"><pre><span></span><span class="n">num_iterations_between_plot</span>
</pre></div>


<p>number of iterations between 2 plot updates during training.</p>
<p>Returns:
    number of iterations or 0 if no plot updates should take place.</p>
<h3 id="pyplotcontext">PyPlotContext</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">PyPlotContext</span><span class="p">(</span>

<span class="p">)</span>
</pre></div>


<p>Contain the context for the maplotlib.pyplot figure plotting.</p>
<p>Attributes
    figure: the figure to plot to
    figsize: figure (width,height) in inches for the figure to be created.
    is_jupyter_active: True if we plot to jupyter notebook cell, False otherwise.
    max_columns: the max number of subplot columns in the pyplot figure</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="n">PyPlotContext</span>(<span class="n">object</span>):

    <span class="s">&quot;&quot;&quot;Contain the context for the maplotlib.pyplot figure plotting.</span>

<span class="s">    Attributes</span>

<span class="s">        figure: the figure to plot to</span>

<span class="s">        figsize: figure (width,height) in inches for the figure to be created.</span>

<span class="s">        is_jupyter_active: True if we plot to jupyter notebook cell, False otherwise.</span>

<span class="s">        max_columns: the max number of subplot columns in the pyplot figure</span>

<span class="s">    &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">__init__</span>(<span class="k">self</span>):

        <span class="k">self</span>.<span class="n">_created_subplots</span> = <span class="n">PlotType</span>.<span class="n">NONE</span>

        <span class="k">self</span>.<span class="n">figure:</span> <span class="n">Optional</span>[<span class="n">plt</span>.<span class="n">Figure</span>] = <span class="n">None</span>

        <span class="k">self</span>.<span class="n">figsize:</span> (<span class="n">float</span>, <span class="n">float</span>) = (<span class="mi">17</span>, <span class="mi">6</span>)

        <span class="k">self</span>.<span class="n">_call_jupyter_display</span> = <span class="nb">False</span>

        <span class="k">self</span>.<span class="n">is_jupyter_active</span> = <span class="nb">False</span>

        <span class="k">self</span>.<span class="n">max_columns</span> = <span class="mi">3</span>

    <span class="n">def</span> <span class="n">__str__</span>(<span class="k">self</span>):

        <span class="n">figure_number</span> = <span class="n">None</span>

        <span class="n">figure_axes_len</span> = <span class="mi">0</span>

        <span class="k">if</span> <span class="k">self</span>.<span class="n">figure:</span>

            <span class="n">figure_number</span> = <span class="k">self</span>.<span class="n">figure</span>.<span class="n">number</span>

            <span class="k">if</span> <span class="k">self</span>.<span class="n">figure</span>.<span class="n">axes:</span>

                <span class="n">figure_axes_len</span> = <span class="n">len</span>(<span class="k">self</span>.<span class="n">figure</span>.<span class="n">axes</span>)

        <span class="k">return</span> <span class="n">f&#39;is_jupyter_active</span>={<span class="k">self</span>.<span class="n">is_jupyter_active</span>} <span class="n">max_columns</span>={<span class="k">self</span>.<span class="n">max_columns</span>} <span class="s">&#39; + \</span>

<span class="s">               f&#39;</span><span class="n">_created_subplots</span>={<span class="k">self</span>.<span class="n">_created_subplots</span>} <span class="n">figure</span>={<span class="n">figure_number</span>} <span class="n">axes</span>={<span class="n">figure_axes_len</span>} &#39;

    <span class="n">def</span> <span class="n">_is_subplot_created</span>(<span class="k">self</span>, <span class="n">plot_type:</span> <span class="n">PlotType</span>):

        <span class="s">&quot;&quot;&quot;Yields true if a subplot of type plot_type was created by a plot callback.&quot;&quot;&quot;</span>

        <span class="n">result</span> = ((<span class="k">self</span>.<span class="n">_created_subplots</span> &amp; <span class="n">plot_type</span>) != <span class="n">PlotType</span>.<span class="n">NONE</span>)

        <span class="k">return</span> <span class="n">result</span>
</pre></div>


</details>
<hr />
<h3 id="stepstraincontext">StepsTrainContext</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">StepsTrainContext</span><span class="p">(</span>

<span class="p">)</span>
</pre></div>


<p>Base class for all agent which evaluate a number of steps during each iteration:</p>
<p>The train loop proceeds roughly as follows:
    for i in num_iterations
        for s in num_steps_per_iterations
            play episodes and record steps
        train policy for num_epochs_per_iteration epochs
        if current_episode % num_iterations_between_eval == 0:
            evaluate policy
        if training_done
            break</p>
<p>Attributes:
    num_steps_per_iteration: number of steps played for each iteration
    num_steps_buffer_preload: number of initial collect steps to preload the buffer
    num_steps_sampled_from_buffer: the number of steps sampled from buffer for each iteration training</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="n">StepsTrainContext</span>(<span class="n">TrainContext</span>):

    <span class="s">&quot;&quot;&quot;Base class for all agent which evaluate a number of steps during each iteration:</span>

<span class="s">        The train loop proceeds roughly as follows:</span>

<span class="s">            for i in num_iterations</span>

<span class="s">                for s in num_steps_per_iterations</span>

<span class="s">                    play episodes and record steps</span>

<span class="s">                train policy for num_epochs_per_iteration epochs</span>

<span class="s">                if current_episode % num_iterations_between_eval == 0:</span>

<span class="s">                    evaluate policy</span>

<span class="s">                if training_done</span>

<span class="s">                    break</span>

<span class="s">        Attributes:</span>

<span class="s">            num_steps_per_iteration: number of steps played for each iteration</span>

<span class="s">            num_steps_buffer_preload: number of initial collect steps to preload the buffer</span>

<span class="s">            num_steps_sampled_from_buffer: the number of steps sampled from buffer for each iteration training</span>

<span class="s">    &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">__init__</span>(<span class="k">self</span>):

        <span class="n">super</span>().<span class="n">__init__</span>()

        <span class="k">self</span>.<span class="n">num_iterations</span> = <span class="mi">20000</span>

        <span class="k">self</span>.<span class="n">num_iterations_between_eval</span> = <span class="mi">1000</span>

        <span class="k">self</span>.<span class="n">num_steps_per_iteration:</span> <span class="nb">int</span> = <span class="mi">1</span>

        <span class="k">self</span>.<span class="n">num_steps_buffer_preload:</span> <span class="nb">int</span> = <span class="mi">1000</span>

        <span class="k">self</span>.<span class="n">num_steps_sampled_from_buffer:</span> <span class="nb">int</span> = <span class="mi">64</span>

        <span class="k">self</span>.<span class="n">max_steps_in_buffer</span> = <span class="mi">100000</span>

    <span class="n">def</span> <span class="n">__str__</span>(<span class="k">self</span>):

        <span class="k">return</span> <span class="n">super</span>().<span class="n">__str__</span>() + \

               <span class="n">f&#39;</span><span class="c1">#steps_per_iteration={self.num_steps_per_iteration} &#39; + \</span>

               <span class="n">f&#39;</span><span class="c1">#steps_buffer_preload={self.num_steps_buffer_preload} &#39; + \</span>

               <span class="n">f&#39;</span><span class="c1">#steps_sampled_from_buffer={self.num_steps_sampled_from_buffer} &#39;</span>

    <span class="n">def</span> <span class="n">_validate</span>(<span class="k">self</span>):

        <span class="s">&quot;&quot;&quot;Validates the consistency of all values, raising an exception if an inadmissible combination is detected.&quot;&quot;&quot;</span>

        <span class="n">super</span>().<span class="n">_validate</span>()

        <span class="n">assert</span> <span class="k">self</span>.<span class="n">num_steps_per_iteration</span> &gt; <span class="mi">0</span>, <span class="s">&quot;num_steps_per_iteration not admissible&quot;</span>
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro_5">Ancestors (in MRO)</h4>
<ul>
<li>easyagents.core.TrainContext</li>
</ul>
<h4 id="instance-variables_5">Instance variables</h4>
<div class="codehilite"><pre><span></span><span class="n">num_iterations_between_plot</span>
</pre></div>


<p>number of iterations between 2 plot updates during training.</p>
<p>Returns:
    number of iterations or 0 if no plot updates should take place.</p>
<h3 id="traincontext">TrainContext</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">TrainContext</span><span class="p">(</span>

<span class="p">)</span>
</pre></div>


<p>Contains the configuration of an agents train method like the number of iterations or the learning rate
along with data gathered sofar during the training which is identical for all implementations.</p>
<p>Hints:
o TrainContext contains all the parameters needed to control the train loop.
o Subclasses of TrainContext may contain additional Agent (but not backend) specific parameters.</p>
<p>Attributes:
    num_iterations: number of times the training is repeated (with additional data), unlimited if None
    max_steps_per_episode: maximum number of steps per episode
    learning_rate: the learning rate used in the next iteration's policy training (0,1]
    reward_discount_gamma: the factor by which a reward is discounted for each step (0,1]
    max_steps_in_buffer: size of the agents buffer in steps</p>
<div class="codehilite"><pre><span></span><span class="n">training_done</span><span class="o">:</span> <span class="k">if</span> <span class="kc">true</span> <span class="n">the</span> <span class="n">train</span> <span class="n">loop</span> <span class="k">is</span> <span class="n">terminated</span> <span class="n">at</span> <span class="n">the</span> <span class="n">end</span> <span class="n">of</span> <span class="n">the</span> <span class="n">current</span> <span class="n">iteration</span>
<span class="n">iterations_done_in_training</span><span class="o">:</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">iterations</span> <span class="n">completed</span> <span class="n">so</span> <span class="n">far</span> <span class="o">(</span><span class="n">during</span> <span class="n">training</span><span class="o">)</span>
<span class="n">episodes_done_in_iteration</span><span class="o">:</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">episodes</span> <span class="n">completed</span> <span class="k">in</span> <span class="n">the</span> <span class="n">current</span> <span class="n">iteration</span>
<span class="n">episodes_done_in_training</span><span class="o">:</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">episodes</span> <span class="n">completed</span> <span class="n">over</span> <span class="n">all</span> <span class="n">iterations</span> <span class="n">so</span> <span class="n">far</span><span class="o">.</span>
    <span class="n">The</span> <span class="n">episodes</span> <span class="n">played</span> <span class="k">for</span> <span class="n">evaluation</span> <span class="n">are</span> <span class="n">not</span> <span class="n">included</span> <span class="k">in</span> <span class="k">this</span> <span class="n">count</span><span class="o">.</span>
<span class="n">steps_done_in_training</span><span class="o">:</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">steps</span> <span class="n">taken</span> <span class="n">over</span> <span class="n">all</span> <span class="n">iterations</span> <span class="n">so</span> <span class="n">far</span>
<span class="n">steps_done_in_iteration</span><span class="o">:</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">steps</span> <span class="n">taken</span> <span class="k">in</span> <span class="n">the</span> <span class="n">current</span> <span class="n">iteration</span>

<span class="n">num_iterations_between_eval</span><span class="o">:</span> <span class="n">number</span> <span class="n">of</span> <span class="n">training</span> <span class="n">iterations</span> <span class="n">before</span> <span class="n">the</span> <span class="n">current</span> <span class="n">policy</span> <span class="k">is</span> <span class="n">evaluated</span><span class="o">.</span>
<span class="n">num_episodes_per_eval</span><span class="o">:</span> <span class="n">number</span> <span class="n">of</span> <span class="n">episodes</span> <span class="n">played</span> <span class="n">to</span> <span class="n">estimate</span> <span class="n">the</span> <span class="n">average</span> <span class="k">return</span> <span class="n">and</span> <span class="n">steps</span>
<span class="n">eval_rewards</span><span class="o">:</span> <span class="n">dict</span> <span class="n">containg</span> <span class="n">the</span> <span class="n">rewards</span> <span class="n">statistics</span> <span class="k">for</span> <span class="k">each</span> <span class="n">policy</span> <span class="n">evaluation</span><span class="o">.</span>
    <span class="n">Each</span> <span class="n">entry</span> <span class="n">contains</span> <span class="n">the</span> <span class="n">tuple</span> <span class="o">(</span><span class="n">min</span><span class="o">,</span> <span class="n">average</span><span class="o">,</span> <span class="n">max</span><span class="o">)</span> <span class="n">over</span> <span class="n">the</span> <span class="n">sum</span> <span class="n">of</span> <span class="n">rewards</span> <span class="n">over</span> <span class="n">all</span> <span class="n">episodes</span>
    <span class="n">played</span> <span class="k">for</span> <span class="n">the</span> <span class="n">current</span> <span class="n">evaluation</span><span class="o">.</span> <span class="n">The</span> <span class="n">dict</span> <span class="k">is</span> <span class="n">indexed</span> <span class="n">by</span> <span class="n">the</span> <span class="n">current_episode</span><span class="o">.</span>
<span class="n">eval_steps</span><span class="o">:</span> <span class="n">dict</span> <span class="n">containg</span> <span class="n">the</span> <span class="n">steps</span> <span class="n">statistics</span> <span class="k">for</span> <span class="k">each</span> <span class="n">policy</span> <span class="n">evaluation</span><span class="o">.</span>
    <span class="n">Each</span> <span class="n">entry</span> <span class="n">contains</span> <span class="n">the</span> <span class="n">tuple</span> <span class="o">(</span><span class="n">min</span><span class="o">,</span> <span class="n">average</span><span class="o">,</span> <span class="n">max</span><span class="o">)</span> <span class="n">over</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">step</span> <span class="n">over</span> <span class="n">all</span> <span class="n">episodes</span>
    <span class="n">played</span> <span class="k">for</span> <span class="n">the</span> <span class="n">current</span> <span class="n">evaluation</span><span class="o">.</span> <span class="n">The</span> <span class="n">dict</span> <span class="k">is</span> <span class="n">indexed</span> <span class="n">by</span> <span class="n">the</span> <span class="n">current_episode</span><span class="o">.</span>
<span class="n">loss</span><span class="o">:</span> <span class="n">dict</span> <span class="n">containing</span> <span class="n">the</span> <span class="n">loss</span> <span class="k">for</span> <span class="k">each</span> <span class="n">iteration</span> <span class="n">training</span><span class="o">.</span> <span class="n">The</span> <span class="n">dict</span> <span class="k">is</span> <span class="n">indexed</span> <span class="n">by</span> <span class="n">the</span> <span class="n">current_episode</span><span class="o">.</span>
</pre></div>


<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="n">TrainContext</span><span class="p">(</span><span class="k">object</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Contains the configuration of an agents train method like the number of iterations or the learning rate</span>

<span class="ss">        along with data gathered sofar during the training which is identical for all implementations.</span>

<span class="ss">        Hints:</span>

<span class="ss">        o TrainContext contains all the parameters needed to control the train loop.</span>

<span class="ss">        o Subclasses of TrainContext may contain additional Agent (but not backend) specific parameters.</span>

<span class="ss">        Attributes:</span>

<span class="ss">            num_iterations: number of times the training is repeated (with additional data), unlimited if None</span>

<span class="ss">            max_steps_per_episode: maximum number of steps per episode</span>

<span class="ss">            learning_rate: the learning rate used in the next iteration&#39;s policy training (0,1]</span>

<span class="ss">            reward_discount_gamma: the factor by which a reward is discounted for each step (0,1]</span>

<span class="ss">            max_steps_in_buffer: size of the agents buffer in steps</span>

<span class="ss">            training_done: if true the train loop is terminated at the end of the current iteration</span>

<span class="ss">            iterations_done_in_training: the number of iterations completed so far (during training)</span>

<span class="ss">            episodes_done_in_iteration: the number of episodes completed in the current iteration</span>

<span class="ss">            episodes_done_in_training: the number of episodes completed over all iterations so far.</span>

<span class="ss">                The episodes played for evaluation are not included in this count.</span>

<span class="ss">            steps_done_in_training: the number of steps taken over all iterations so far</span>

<span class="ss">            steps_done_in_iteration: the number of steps taken in the current iteration</span>

<span class="ss">            num_iterations_between_eval: number of training iterations before the current policy is evaluated.</span>

<span class="ss">            num_episodes_per_eval: number of episodes played to estimate the average return and steps</span>

<span class="ss">            eval_rewards: dict containg the rewards statistics for each policy evaluation.</span>

<span class="ss">                Each entry contains the tuple (min, average, max) over the sum of rewards over all episodes</span>

<span class="ss">                played for the current evaluation. The dict is indexed by the current_episode.</span>

<span class="ss">            eval_steps: dict containg the steps statistics for each policy evaluation.</span>

<span class="ss">                Each entry contains the tuple (min, average, max) over the number of step over all episodes</span>

<span class="ss">                played for the current evaluation. The dict is indexed by the current_episode.</span>

<span class="ss">            loss: dict containing the loss for each iteration training. The dict is indexed by the current_episode.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">num_iterations</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">int</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">max_steps_per_episode</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1000</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">num_iterations_between_eval</span><span class="p">:</span><span class="w"> </span><span class="nc">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">num_episodes_per_eval</span><span class="p">:</span><span class="w"> </span><span class="nc">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">learning_rate</span><span class="p">:</span><span class="w"> </span><span class="nc">float</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.001</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">reward_discount_gamma</span><span class="p">:</span><span class="w"> </span><span class="nc">float</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">max_steps_in_buffer</span><span class="p">:</span><span class="w"> </span><span class="nc">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">100000</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">training_done</span><span class="p">:</span><span class="w"> </span><span class="n">bool</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">iterations_done_in_training</span><span class="p">:</span><span class="w"> </span><span class="nc">int</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">episodes_done_in_iteration</span><span class="p">:</span><span class="w"> </span><span class="nc">int</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">episodes_done_in_training</span><span class="p">:</span><span class="w"> </span><span class="nc">int</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">steps_done_in_training</span><span class="p">:</span><span class="w"> </span><span class="nc">int</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">steps_done_in_iteration</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">loss</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">int, float</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">eval_rewards</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">int, Tuple[float, float, float</span><span class="o">]</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="nl">eval_steps</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">int, Tuple[float, float, float</span><span class="o">]</span><span class="err">]</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__str__</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">f</span><span class="s1">&#39;training_done={self.training_done} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;#iterations_done_in_training={self.iterations_done_in_training} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;#episodes_done_in_iteration={self.episodes_done_in_iteration} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;#steps_done_in_iteration={self.steps_done_in_iteration} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;#iterations={self.num_iterations} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;#max_steps_per_episode={self.max_steps_per_episode} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;#iterations_between_eval={self.num_iterations_between_eval} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;#episodes_per_eval={self.num_episodes_per_eval} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;#learning_rate={self.learning_rate} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;#reward_discount_gamma={self.reward_discount_gamma} &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">               </span><span class="n">f</span><span class="s1">&#39;#max_steps_in_buffer={self.max_steps_in_buffer} &#39;</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">_reset</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Clears all values modified during a train() call.&quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">training_done</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">False</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">iterations_done_in_training</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">episodes_done_in_iteration</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">episodes_done_in_training</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">steps_done_in_training</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">steps_done_in_iteration</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dict</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">eval_rewards</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dict</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">eval_steps</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dict</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">_validate</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Validates the consistency of all values, raising an exception if an inadmissible combination is detected.&quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">num_iterations</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">num_iterations</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;num_iterations not admissible&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">max_steps_per_episode</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;max_steps_per_episode not admissible&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">num_iterations_between_eval</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;num_iterations_between_eval not admissible&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">num_episodes_per_eval</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;num_episodes_per_eval not admissible&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">learning_rate</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;learning_rate not in interval (0,1]&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">assert</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">reward_discount_gamma</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;reward_discount_gamma not in interval (0,1]&quot;</span><span class="w"></span>

<span class="w">    </span><span class="nv">@property</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">num_iterations_between_plot</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;number of iterations between 2 plot updates during training.</span>

<span class="ss">        Returns:</span>

<span class="ss">            number of iterations or 0 if no plot updates should take place.</span>

<span class="ss">            &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">num_iterations_between_eval</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">math</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_iterations_between_eval</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">result</span><span class="w"></span>
</pre></div>


</details>
<hr />
<h4 id="descendants_2">Descendants</h4>
<ul>
<li>easyagents.core.EpisodesTrainContext</li>
<li>easyagents.core.StepsTrainContext</li>
</ul>
<h4 id="instance-variables_6">Instance variables</h4>
<div class="codehilite"><pre><span></span><span class="n">num_iterations_between_plot</span>
</pre></div>


<p>number of iterations between 2 plot updates during training.</p>
<p>Returns:
    number of iterations or 0 if no plot updates should take place.</p>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../agents/" title="Agents" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Agents
              </span>
            </div>
          </a>
        
        
          <a href="../env/" title="Env" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Env
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Powered by
        <a href="http://timothycrosley.github.io/portray">portray.</a>
        You too can
        <a href="http://timothycrosley.github.io/portray">
          portray</a>
        your Python project well using automatic documentation.
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../assets/javascripts/application.808e90bb.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../.."}})</script>
      
    
  </body>
</html>