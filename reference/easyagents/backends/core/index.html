



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.6.0">
    
    
      
        <title>Core - easyagents</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/application.1b62728e.css">
      
        <link rel="stylesheet" href="../../../../assets/stylesheets/application-palette.a8b3c06d.css">
      
      
        
        
        <meta name="theme-color" content="#4caf50">
      
    
    
      <script src="../../../../assets/javascripts/modernizr.268332fc.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../../../assets/fonts/material-icons.css">
    
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="green" data-md-color-accent="lightgreen">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#module-easyagentsbackendscore" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../.." title="easyagents" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              easyagents
            </span>
            <span class="md-header-nav__topic">
              
                Core
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/christianhidber/easyagents/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    easyagents
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../.." title="easyagents" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    easyagents
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/christianhidber/easyagents/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    easyagents
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../../../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../CODE_OF_CONDUCT/" title="Code Of Conduct" class="md-nav__link">
      Code Of Conduct
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../CONTRIBUTING/" title="Contributing" class="md-nav__link">
      Contributing
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../documentation/Markdown/Release_Notes/" title="Release Notes" class="md-nav__link">
      Release Notes
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5" checked>
    
    <label class="md-nav__link" for="nav-5">
      Reference
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Reference
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1" type="checkbox" id="nav-5-1" checked>
    
    <label class="md-nav__link" for="nav-5-1">
      Easyagents
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-1">
        Easyagents
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../agents/" title="Agents" class="md-nav__link">
      Agents
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../core/" title="Core" class="md-nav__link">
      Core
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1-3" type="checkbox" id="nav-5-1-3" checked>
    
    <label class="md-nav__link" for="nav-5-1-3">
      Backends
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-1-3">
        Backends
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Core
      </label>
    
    <a href="./" title="Core" class="md-nav__link md-nav__link--active">
      Core
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backendagent" class="md-nav__link">
    BackendAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#load" class="md-nav__link">
    load
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_implementation" class="md-nav__link">
    load_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_implementation" class="md-nav__link">
    save_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backendagentfactory" class="md-nav__link">
    BackendAgentFactory
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants_1" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_agent" class="md-nav__link">
    create_agent
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_algorithms" class="md-nav__link">
    get_algorithms
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../tfagents/" title="Tfagents" class="md-nav__link">
      Tfagents
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1-4" type="checkbox" id="nav-5-1-4">
    
    <label class="md-nav__link" for="nav-5-1-4">
      Callbacks
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-1-4">
        Callbacks
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../callbacks/duration/" title="Duration" class="md-nav__link">
      Duration
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../callbacks/log/" title="Log" class="md-nav__link">
      Log
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../callbacks/plot/" title="Plot" class="md-nav__link">
      Plot
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../callbacks/save/" title="Save" class="md-nav__link">
      Save
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backendagent" class="md-nav__link">
    BackendAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#load" class="md-nav__link">
    load
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_implementation" class="md-nav__link">
    load_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save" class="md-nav__link">
    save
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_implementation" class="md-nav__link">
    save_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backendagentfactory" class="md-nav__link">
    BackendAgentFactory
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants_1" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_agent" class="md-nav__link">
    create_agent
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_algorithms" class="md-nav__link">
    get_algorithms
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/christianhidber/easyagents/edit/master/reference/easyagents/backends/core.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="module-easyagentsbackendscore">Module easyagents.backends.core</h1>
<p>This module contains backend core classes like Backend and BackendAgent.</p>
<p>The concrete backends like tfagent or baselines are implemented in seprate modules.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="sd">&quot;&quot;&quot;This module contains backend core classes like Backend and BackendAgent.</span>

<span class="sd">    The concrete backends like tfagent or baselines are implemented in seprate modules.</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">ABCMeta</span><span class="p">,</span> <span class="n">abstractmethod</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Dict</span>

<span class="kn">import</span> <span class="nn">datetime</span>

<span class="kn">import</span> <span class="nn">gym</span>

<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">shutil</span>

<span class="kn">import</span> <span class="nn">tempfile</span>

<span class="kn">import</span> <span class="nn">tensorflow</span>

<span class="kn">import</span> <span class="nn">numpy</span>

<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">from</span> <span class="nn">easyagents</span> <span class="kn">import</span> <span class="n">core</span>

<span class="kn">from</span> <span class="nn">easyagents.backends</span> <span class="kn">import</span> <span class="n">monitor</span>

<span class="kn">from</span> <span class="nn">easyagents.callbacks</span> <span class="kn">import</span> <span class="n">plot</span>

<span class="n">_tf_eager_execution_active</span> <span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">def</span> <span class="nf">_get_temp_path</span><span class="p">():</span>

    <span class="sd">&quot;&quot;&quot;Yields a path to a non-existent temporary directory inside the systems temp path.&quot;&quot;&quot;</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tempfile</span><span class="o">.</span><span class="n">gettempdir</span><span class="p">(),</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">gettempprefix</span><span class="p">())</span>

    <span class="n">n</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">result</span> <span class="o">+</span> <span class="sa">f</span><span class="s1">&#39;-{n.year % 100:2}</span><span class="si">{n.month:02}{n.day:02}</span><span class="s1">-</span><span class="si">{n.hour:02}{n.minute:02}{n.second:02}</span><span class="s1">-&#39;</span> <span class="o">+</span> \

             <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{n.microsecond:06}</span><span class="s1">&#39;</span>

    <span class="k">return</span> <span class="n">result</span>

<span class="k">def</span> <span class="nf">_mkdir</span><span class="p">(</span><span class="n">directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Creates a directory with the given path. NoOps if the directory already exists.</span>

<span class="sd">        If a file exists at path, the file is removed.</span>

<span class="sd">        Returns:</span>

<span class="sd">            the absolute path to directory</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">directory</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">directory</span><span class="p">):</span>

        <span class="n">_rmpath</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>

    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">directory</span>

<span class="k">def</span> <span class="nf">_rmpath</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Removes the file or directory and its content. NoOps if the directory does not exist.</span>

<span class="sd">    Errors are ignored.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">path</span><span class="p">:</span>

        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>

            <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>

            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">_BackendEvalCallback</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Evaluates an agents current policy and updates its train_context accordingly.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span><span class="p">):</span>

        <span class="k">assert</span> <span class="n">train_context</span><span class="p">,</span> <span class="s2">&quot;train_context not set&quot;</span>

        <span class="k">assert</span> <span class="n">train_context</span><span class="o">.</span><span class="n">num_episodes_per_eval</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;num_episodes_per_eval is 0.&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_train_contex</span> <span class="o">=</span> <span class="n">train_context</span>

    <span class="k">def</span> <span class="nf">on_play_episode_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span><span class="p">):</span>

        <span class="n">pc</span> <span class="o">=</span> <span class="n">agent_context</span><span class="o">.</span><span class="n">play</span>

        <span class="n">tc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_contex</span>

        <span class="n">sum_of_r</span> <span class="o">=</span> <span class="n">pc</span><span class="o">.</span><span class="n">sum_of_rewards</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>

        <span class="n">tc</span><span class="o">.</span><span class="n">eval_rewards</span><span class="p">[</span><span class="n">tc</span><span class="o">.</span><span class="n">episodes_done_in_training</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>

            <span class="nb">min</span><span class="p">(</span><span class="n">sum_of_r</span><span class="p">),</span> <span class="nb">sum</span><span class="p">(</span><span class="n">sum_of_r</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">sum_of_r</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">sum_of_r</span><span class="p">))</span>

        <span class="n">steps</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">)</span> <span class="k">for</span> <span class="n">episode_rewards</span> <span class="ow">in</span> <span class="n">pc</span><span class="o">.</span><span class="n">rewards</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>

        <span class="n">tc</span><span class="o">.</span><span class="n">eval_steps</span><span class="p">[</span><span class="n">tc</span><span class="o">.</span><span class="n">episodes_done_in_training</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">steps</span><span class="p">),</span> <span class="nb">sum</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">steps</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">_BackendAgent</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Base class for all backend agent implementations.</span>

<span class="sd">        Implements the train loop and calls the Callbacks.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_config</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span><span class="p">,</span> <span class="n">backend_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">tf_eager_execution</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>

<span class="sd">            model_config: defines the model and environment to be used</span>

<span class="sd">            backend_name: id of the backend to which this agent belongs to.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">global</span> <span class="n">_tf_eager_execution_active</span>

        <span class="k">assert</span> <span class="n">model_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;model_config not set.&quot;</span>

        <span class="k">assert</span> <span class="n">backend_name</span>

        <span class="k">if</span> <span class="n">_tf_eager_execution_active</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">_tf_eager_execution_active</span> <span class="o">=</span> <span class="n">tf_eager_execution</span>

        <span class="k">assert</span> <span class="n">_tf_eager_execution_active</span> <span class="o">==</span> <span class="n">tf_eager_execution</span><span class="p">,</span> \

            <span class="s2">&quot;Due to an incompatibility between tensorforce and tfagents their agents can not be instantiated in the&quot;</span> <span class="o">+</span>\

            <span class="s2">&quot;same python runtime instance (conflicting excpectations on tensorflows eager execution mode).&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_backend_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">backend_name</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="n">model_config</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">AgentContext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_totals</span> <span class="o">=</span> <span class="n">monitor</span><span class="o">.</span><span class="n">_register_gym_monitor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">original_env_name</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gym_env_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_totals</span><span class="o">.</span><span class="n">gym_env_name</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="o">.</span><span class="n">_PreProcessCallback</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">plot</span><span class="o">.</span><span class="n">_PreProcess</span><span class="p">()]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_postprocess_callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="o">.</span><span class="n">_PostProcessCallback</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">plot</span><span class="o">.</span><span class="n">_PostProcess</span><span class="p">()]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_train_total_episodes_on_iteration_begin</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">_set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot; sets the random seeds for all dependent packages &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="kp">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="kp">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="kp">seed</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;tf.random.set_seed&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;(seed=</span><span class="si">{seed}</span><span class="s1">)&#39;</span><span class="p">)</span>

            <span class="n">tensorflow</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="kp">seed</span><span class="o">=</span><span class="kp">seed</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;numpy.random.seed&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;(</span><span class="si">{seed}</span><span class="s1">)&#39;</span><span class="p">)</span>

            <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="kp">seed</span><span class="p">(</span><span class="kp">seed</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;random.seed&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;(</span><span class="si">{seed}</span><span class="s1">)&#39;</span><span class="p">)</span>

            <span class="n">random</span><span class="o">.</span><span class="kp">seed</span><span class="p">(</span><span class="kp">seed</span><span class="p">)</span>

        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">_eval_current_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Evaluates the current policy using play and updates the train_context</span>

<span class="sd">            If num_episodes_per_eval or num_iterations_per_eval is 0 no evaluation is performed.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">train</span>

        <span class="k">assert</span> <span class="n">tc</span><span class="p">,</span> <span class="s2">&quot;train_context not set&quot;</span>

        <span class="k">if</span> <span class="n">tc</span><span class="o">.</span><span class="n">num_episodes_per_eval</span> <span class="ow">and</span> <span class="n">tc</span><span class="o">.</span><span class="n">num_iterations_between_eval</span><span class="p">:</span>

            <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">_BackendEvalCallback</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">train</span><span class="p">)]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">play</span><span class="p">(</span><span class="n">play_context</span><span class="o">=</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">train</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">log_api</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">api_target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">log_msg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Logs a call to api_target with additional log_msg.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">api_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">api_target</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">if</span> <span class="n">log_msg</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_api_log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">,</span> <span class="n">api_target</span><span class="p">,</span> <span class="n">log_msg</span><span class="o">=</span><span class="n">log_msg</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">log</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_msg</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Logs msg.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">log_msg</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">,</span> <span class="n">log_msg</span><span class="o">=</span><span class="n">log_msg</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_on_gym_init_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;called when the monitored environment begins the instantiation of a new gym environment.</span>

<span class="sd">        Hint:</span>

<span class="sd">            the total instances count is not incremented yet.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_gym_init_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_on_gym_init_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">monitor</span><span class="o">.</span><span class="n">_MonitorEnv</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;called when the monitored environment completed the instantiation of a new gym environment.</span>

<span class="sd">        Hint:</span>

<span class="sd">            o the total instances count is incremented by now</span>

<span class="sd">            o the new env (and its action space) is seeded with the api_context&#39;s seed</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="n">env</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="kp">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">gym_env</span>

            <span class="kp">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="kp">seed</span>

            <span class="n">env</span><span class="o">.</span><span class="kp">seed</span><span class="p">(</span><span class="kp">seed</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_gym_init_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_on_gym_reset_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">monitor</span><span class="o">.</span><span class="n">_MonitorEnv</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;called when the monitored environment begins a reset.</span>

<span class="sd">        Hint:</span>

<span class="sd">            the total reset count is not incremented yet.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="n">env</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_gym_reset_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_on_gym_reset_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">monitor</span><span class="o">.</span><span class="n">_MonitorEnv</span><span class="p">,</span> <span class="n">reset_result</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;called when the monitored environment completed a reset.</span>

<span class="sd">        Hint:</span>

<span class="sd">            the total episode count is incremented by now (if a step was performed before the last reset).&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="n">env</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_gym_reset_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">,</span> <span class="n">reset_result</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_on_gym_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">monitor</span><span class="o">.</span><span class="n">_MonitorEnv</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;called when the monitored environment begins a step.</span>

<span class="sd">        Hint:</span>

<span class="sd">            o sets env.max_steps_per_episode if we are in train / play. Thus the episode is ended</span>

<span class="sd">              by the MonitorEnv if the step limit is exceeded</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">ac</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span>

        <span class="n">ac</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="n">env</span>

        <span class="n">env</span><span class="o">.</span><span class="n">max_steps_per_episode</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">ac</span><span class="o">.</span><span class="n">is_play</span> <span class="ow">or</span> <span class="n">ac</span><span class="o">.</span><span class="n">is_eval</span><span class="p">:</span>

            <span class="n">env</span><span class="o">.</span><span class="n">max_steps_per_episode</span> <span class="o">=</span> <span class="n">ac</span><span class="o">.</span><span class="n">play</span><span class="o">.</span><span class="n">max_steps_per_episode</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_on_play_step_begin</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">ac</span><span class="o">.</span><span class="n">is_train</span><span class="p">:</span>

            <span class="n">env</span><span class="o">.</span><span class="n">max_steps_per_episode</span> <span class="o">=</span> <span class="n">ac</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">max_steps_per_episode</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_on_train_step_begin</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_gym_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_on_gym_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">monitor</span><span class="o">.</span><span class="n">_MonitorEnv</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">step_result</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;called when the monitored environment completed a step.</span>

<span class="sd">        Args:</span>

<span class="sd">            env: the gym_env the last step was done on</span>

<span class="sd">            step_result: the result (state, reward, done, info) of the last step call</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">ac</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span>

        <span class="n">ac</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="n">env</span>

        <span class="k">if</span> <span class="n">ac</span><span class="o">.</span><span class="n">is_play</span> <span class="ow">or</span> <span class="n">ac</span><span class="o">.</span><span class="n">is_eval</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_on_play_step_end</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">step_result</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">ac</span><span class="o">.</span><span class="n">is_train</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_on_train_step_end</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">step_result</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_gym_step_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">step_result</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">env</span><span class="o">.</span><span class="n">max_steps_per_episode</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_on_play_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Must NOT be called by play_implementation&quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_play_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_on_play_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Must NOT be called by play_implementation&quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_play_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">play</span><span class="o">.</span><span class="n">gym_env</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">on_play_episode_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Env</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Must be called by play_implementation at the beginning of a new episode</span>

<span class="sd">        Args:</span>

<span class="sd">            env: the gym environment used to play the episode.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="n">env</span><span class="p">,</span> <span class="s2">&quot;env not set.&quot;</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Env</span><span class="p">),</span> <span class="s2">&quot;env not an an instance of gym.Env.&quot;</span>

        <span class="n">pc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">play</span>

        <span class="n">pc</span><span class="o">.</span><span class="n">gym_env</span> <span class="o">=</span> <span class="n">env</span>

        <span class="n">pc</span><span class="o">.</span><span class="n">steps_done_in_episode</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">pc</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="n">pc</span><span class="o">.</span><span class="n">episodes_done</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">pc</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="n">pc</span><span class="o">.</span><span class="n">episodes_done</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">pc</span><span class="o">.</span><span class="n">sum_of_rewards</span><span class="p">[</span><span class="n">pc</span><span class="o">.</span><span class="n">episodes_done</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_play_episode_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_play_episode_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Must be called by play_implementation at the end of an episode&quot;&quot;&quot;</span>

        <span class="n">pc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">play</span>

        <span class="n">pc</span><span class="o">.</span><span class="n">episodes_done</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">pc</span><span class="o">.</span><span class="n">num_episodes</span> <span class="ow">and</span> <span class="n">pc</span><span class="o">.</span><span class="n">episodes_done</span> <span class="o">&gt;=</span> <span class="n">pc</span><span class="o">.</span><span class="n">num_episodes</span><span class="p">:</span>

            <span class="n">pc</span><span class="o">.</span><span class="n">play_done</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_play_episode_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_on_play_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called before each call to gym.step on the current play env (agent_context.play.gym_env)</span>

<span class="sd">            Args:</span>

<span class="sd">                action: the action to be passed to the upcoming gym_env.step call</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_play_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_on_play_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">step_result</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called after each call to gym.step on the current play env (agent_context.play.gym_env)</span>

<span class="sd">        Args:</span>

<span class="sd">            step_result: the result (state, reward, done, info) of the last step call</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="kp">info</span><span class="p">)</span> <span class="o">=</span> <span class="n">step_result</span>

        <span class="n">pc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">play</span>

        <span class="n">pc</span><span class="o">.</span><span class="n">steps_done_in_episode</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">pc</span><span class="o">.</span><span class="n">steps_done</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">pc</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="n">pc</span><span class="o">.</span><span class="n">episodes_done</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="kp">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="n">pc</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="n">pc</span><span class="o">.</span><span class="n">episodes_done</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="kp">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>

        <span class="n">pc</span><span class="o">.</span><span class="n">sum_of_rewards</span><span class="p">[</span><span class="n">pc</span><span class="o">.</span><span class="n">episodes_done</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">reward</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_play_step_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">step_result</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Must NOT be called by train_implementation&quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Must NOT be called by train_implementation&quot;&quot;&quot;</span>

        <span class="n">tc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">train</span>

        <span class="k">if</span> <span class="n">tc</span><span class="o">.</span><span class="n">episodes_done_in_training</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tc</span><span class="o">.</span><span class="n">eval_rewards</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_eval_current_policy</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_iteration_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Must be called by train_implementation at the begining of a new iteration&quot;&quot;&quot;</span>

        <span class="n">tc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">train</span>

        <span class="n">tc</span><span class="o">.</span><span class="n">episodes_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">tc</span><span class="o">.</span><span class="n">steps_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">tc</span><span class="o">.</span><span class="n">iterations_done_in_training</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_eval_current_policy</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_totals</span><span class="o">.</span><span class="n">episodes_done</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_train_iteration_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_iteration_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Must be called by train_implementation at the end of an iteration</span>

<span class="sd">        Evaluates the current policy. Use kwargs to set additional dict values in train context.</span>

<span class="sd">        Eg for an ActorCriticTrainContext the losses may be set like this:</span>

<span class="sd">            on_train_iteration(loss=123,actor_loss=456,critic_loss=789)</span>

<span class="sd">        Args:</span>

<span class="sd">            loss: loss after the training of the model in this iteration or math.nan if the loss is not available</span>

<span class="sd">            **kwargs: if a keyword matches a dict property of the TrainContext instance, then</span>

<span class="sd">                        the dict[episodes_done_in_training] is set to the arg.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">train</span>

        <span class="n">totals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">gym</span><span class="o">.</span><span class="n">_totals</span>

        <span class="n">tc</span><span class="o">.</span><span class="n">episodes_done_in_iteration</span> <span class="o">=</span> <span class="p">(</span><span class="n">totals</span><span class="o">.</span><span class="n">episodes_done</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_total_episodes_on_iteration_begin</span><span class="p">)</span>

        <span class="n">tc</span><span class="o">.</span><span class="n">episodes_done_in_training</span> <span class="o">+=</span> <span class="n">tc</span><span class="o">.</span><span class="n">episodes_done_in_iteration</span>

        <span class="n">tc</span><span class="o">.</span><span class="n">loss</span><span class="p">[</span><span class="n">tc</span><span class="o">.</span><span class="n">episodes_done_in_training</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span>

        <span class="c1"># set traincontext dict from kwargs:</span>

        <span class="k">for</span> <span class="n">prop_name</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>

            <span class="n">prop_instance</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">tc</span><span class="p">,</span> <span class="n">prop_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="n">prop_value</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">prop_name</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">prop_instance</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prop_instance</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>

                <span class="n">prop_instance</span><span class="p">[</span><span class="n">tc</span><span class="o">.</span><span class="n">episodes_done_in_training</span><span class="p">]</span> <span class="o">=</span> <span class="n">prop_value</span>

        <span class="n">tc</span><span class="o">.</span><span class="n">iterations_done_in_training</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">tc</span><span class="o">.</span><span class="n">num_iterations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">tc</span><span class="o">.</span><span class="n">training_done</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">iterations_done_in_training</span> <span class="o">&gt;=</span> <span class="n">tc</span><span class="o">.</span><span class="n">num_iterations</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">tc</span><span class="o">.</span><span class="n">num_iterations_between_eval</span> <span class="ow">and</span> <span class="p">(</span><span class="n">tc</span><span class="o">.</span><span class="n">iterations_done_in_training</span> <span class="o">%</span> <span class="n">tc</span><span class="o">.</span><span class="n">num_iterations_between_eval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_eval_current_policy</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="n">c</span><span class="o">.</span><span class="n">on_train_iteration_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_on_train_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called before each call to gym.step on the current train env (agent_context.train.gym_env)</span>

<span class="sd">            Args:</span>

<span class="sd">                action: the action to be passed to the upcoming gym_env.step call</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="sd">&quot;&quot;&quot;Loads a previously trained and saved actor policy from directory.</span>

<span class="sd">        The loaded policy may afterwards be used by calling play().</span>

<span class="sd">        Args:</span>

<span class="sd">            directory: the directory containing the trained policy</span>

<span class="sd">            callbacks: list of callbacks called during the load.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="n">callbacks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;callbacks not set&quot;</span>

        <span class="k">assert</span> <span class="n">directory</span>

        <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">load_implementation</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">_is_policy_trained</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@abstractmethod</span>

    <span class="k">def</span> <span class="nf">load_implementation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Loads a previously trained and saved actor policy from directory.</span>

<span class="sd">        The loaded policy may afterwards be used by calling play().</span>

<span class="sd">        Args:</span>

<span class="sd">            directory: the directory containing the trained policy.</span>

<span class="sd">        &quot;&quot;&quot;</span>

    <span class="c1"># noinspection PyUnusedLocal</span>

    <span class="k">def</span> <span class="nf">_on_train_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="nb">object</span><span class="p">,</span> <span class="n">step_result</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Called after each call to gym.step on the current train env (agent_context.train.gym_env)</span>

<span class="sd">        Args:</span>

<span class="sd">            step_result: the result (state, reward, done, info) of the last step call</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">train</span>

        <span class="n">tc</span><span class="o">.</span><span class="n">steps_done_in_iteration</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">tc</span><span class="o">.</span><span class="n">steps_done_in_training</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">play_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="sd">&quot;&quot;&quot;Forwarding to play_implementation overriden by the subclass.</span>

<span class="sd">            Args:</span>

<span class="sd">                play_context: play configuration to be used</span>

<span class="sd">                callbacks: list of callbacks called during play.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="n">callbacks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;callbacks not set&quot;</span>

        <span class="k">assert</span> <span class="n">play_context</span><span class="p">,</span> <span class="s2">&quot;play_context not set&quot;</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">play</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;play_context already set in agent_context&quot;</span>

        <span class="n">play_context</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">play_context</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">play</span> <span class="o">=</span> <span class="n">play_context</span>

        <span class="n">old_callbacks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="k">try</span><span class="p">:</span>

            <span class="n">monitor</span><span class="o">.</span><span class="n">_MonitorEnv</span><span class="o">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_on_play_begin</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">play_implementation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">play</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_on_play_end</span><span class="p">()</span>

        <span class="k">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="o">.</span><span class="n">_MonitorEnv</span><span class="o">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">old_callbacks</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">play</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@abstractmethod</span>

    <span class="k">def</span> <span class="nf">play_implementation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">play_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Agent specific implementation of playing a single episode with the current policy.</span>

<span class="sd">            For implementation details see BackendBaseAgent.</span>

<span class="sd">        &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="sd">&quot;&quot;&quot;Forwarding to train_implementation overriden by the subclass</span>

<span class="sd">            Args:</span>

<span class="sd">                train_context: training configuration to be used</span>

<span class="sd">                callbacks: list of callbacks called during the training and evaluation.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="n">callbacks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;callbacks not set&quot;</span>

        <span class="k">assert</span> <span class="n">train_context</span><span class="p">,</span> <span class="s2">&quot;train_context not set&quot;</span>

        <span class="n">train_context</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">train_context</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train_context</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">play</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="k">try</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;backend_name&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{self._backend_name}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_set_seed</span><span class="p">()</span>

            <span class="n">monitor</span><span class="o">.</span><span class="n">_MonitorEnv</span><span class="o">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_on_train_begin</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">_is_policy_trained</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">train_implementation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">train</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_on_train_end</span><span class="p">()</span>

        <span class="k">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="o">.</span><span class="n">_MonitorEnv</span><span class="o">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">play</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@abstractmethod</span>

    <span class="k">def</span> <span class="nf">train_implementation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Agent specific implementation of the train loop.</span>

<span class="sd">            For implementational details see BackendBaseAgent.</span>

<span class="sd">        &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="sd">&quot;&quot;&quot;Saves the currently trained actor policy in directory.</span>

<span class="sd">        Only the actor policy is guaranteed to be saved.</span>

<span class="sd">        Thus after a call to load resuming training is not supported.</span>

<span class="sd">        Args:</span>

<span class="sd">            directory: the directory to save the policy weights to. the directory must exist.</span>

<span class="sd">            callbacks: list of callbacks called during policy load.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="n">callbacks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;callbacks not set&quot;</span>

        <span class="k">assert</span> <span class="n">directory</span>

        <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_context</span><span class="o">.</span><span class="n">_is_policy_trained</span><span class="p">,</span> <span class="s2">&quot;No trained policy available.&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">save_implementation</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@abstractmethod</span>

    <span class="k">def</span> <span class="nf">save_implementation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Agent speecific implementation of saving the weights for the actor policy.</span>

<span class="sd">        Save must only guarantee to persist the weights of the actor policy.</span>

<span class="sd">        The implementation may write multiple files with fixed filenames.</span>

<span class="sd">        Args:</span>

<span class="sd">             directory: the (existing) directory to save the policy weights to.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="k">class</span> <span class="nc">BackendAgent</span><span class="p">(</span><span class="n">_BackendAgent</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Base class for all BackendAgent implementation.</span>

<span class="sd">        Explicitely exhibits all methods that should be overriden by an implementing agent.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>

    <span class="k">def</span> <span class="nf">load_implementation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Loads a previously trained and saved actor policy from directory.</span>

<span class="sd">        The loaded policy may afterwards be used by calling play().</span>

<span class="sd">        Args:</span>

<span class="sd">            directory: the directory containing the trained policy.</span>

<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>

    <span class="k">def</span> <span class="nf">play_implementation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">play_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Agent specific implementation of playing a number of episodes with the current policy.</span>

<span class="sd">            The implementation should have the form:</span>

<span class="sd">            while True:</span>

<span class="sd">                on_play_episode_begin(env)</span>

<span class="sd">                state = env.reset()</span>

<span class="sd">                while True:</span>

<span class="sd">                    action = _trained_policy.action(state)</span>

<span class="sd">                    (state, reward, done, info) = env.step(action)</span>

<span class="sd">                    if done:</span>

<span class="sd">                        break</span>

<span class="sd">                on_play_episode_end()</span>

<span class="sd">                if play_context.play_done:</span>

<span class="sd">                    break</span>

<span class="sd">            Args:</span>

<span class="sd">                play_context: play configuration to be used</span>

<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>

    <span class="k">def</span> <span class="nf">save_implementation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Agent speecific implementation of saving the weights for the actor policy.</span>

<span class="sd">        Save must only guarantee to persist the weights of the actor policy.</span>

<span class="sd">        The implementation may write multiple files with fixed filenames.</span>

<span class="sd">        Args:</span>

<span class="sd">             directory: the directory to save the policy weights to.</span>

<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>

    <span class="k">def</span> <span class="nf">train_implementation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Agent specific implementation of the train loop.</span>

<span class="sd">            The implementation should have the form:</span>

<span class="sd">            while True:</span>

<span class="sd">                on_iteration_begin</span>

<span class="sd">                for e in num_episodes_per_iterations</span>

<span class="sd">                    play episode and record steps (while steps_in_episode &lt; max_steps_per_episode and)</span>

<span class="sd">                train policy for num_epochs_per_iteration epochs</span>

<span class="sd">                on_iteration_end( loss )</span>

<span class="sd">                if training_done</span>

<span class="sd">                    break</span>

<span class="sd">            Args:</span>

<span class="sd">                train_context: context configuring the train loop</span>

<span class="sd">            Hints:</span>

<span class="sd">            o the subclasses training loss is passed through to BackendAgent by on_iteration_end.</span>

<span class="sd">              Thus the subclass must not add the experienced loss to the TrainContext.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="k">class</span> <span class="nc">BackendAgentFactory</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Backend agent factory defining the currently available agents (algorithms).</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">backend_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;abstract_BackendAgentFactory&#39;</span>

    <span class="k">def</span> <span class="nf">create_agent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">easyagent_type</span><span class="p">:</span> <span class="n">Type</span><span class="p">,</span> <span class="n">model_config</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span><span class="p">)</span> \

            <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_BackendAgent</span><span class="p">]:</span>

        <span class="sd">&quot;&quot;&quot;Creates a backend agent instance implementing the algorithm given by agent_type.</span>

<span class="sd">        Args:</span>

<span class="sd">            easyagent_type: the EasyAgent derived type for which an implementing backend instance will be created</span>

<span class="sd">            model_config: the model_config passed to the constructor of the backend instance.</span>

<span class="sd">        Returns:</span>

<span class="sd">            instance of the agent or None if not implemented by this backend.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">result</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_BackendAgent</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">algorithms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_algorithms</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">easyagent_type</span> <span class="ow">in</span> <span class="n">algorithms</span><span class="p">:</span>

            <span class="n">result</span> <span class="o">=</span> <span class="n">algorithms</span><span class="p">[</span><span class="n">easyagent_type</span><span class="p">](</span><span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">get_algorithms</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Type</span><span class="p">,</span> <span class="n">Type</span><span class="p">[</span><span class="n">_BackendAgent</span><span class="p">]]:</span>

        <span class="sd">&quot;&quot;&quot;Yields a mapping of EasyAgent types to the implementations provided by this backend.&quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="p">{}</span>
</pre></div>


</details>
<h2 id="classes">Classes</h2>
<h3 id="backendagent">BackendAgent</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">BackendAgent</span><span class="p">(</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span><span class="p">,</span>
    <span class="n">backend_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">tf_eager_execution</span><span class="p">:</span> <span class="nb">bool</span>
<span class="p">)</span>
</pre></div>


<p>Base class for all BackendAgent implementation.</p>
<p>Explicitely exhibits all methods that should be overriden by an implementing agent.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="n">BackendAgent</span><span class="p">(</span><span class="n">_BackendAgent</span><span class="p">,</span><span class="w"> </span><span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Base class for all BackendAgent implementation.</span>

<span class="ss">        Explicitely exhibits all methods that should be overriden by an implementing agent.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="nv">@abstractmethod</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">load_implementation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">directory</span><span class="p">:</span><span class="w"> </span><span class="nf">str</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Loads a previously trained and saved actor policy from directory.</span>

<span class="ss">        The loaded policy may afterwards be used by calling play().</span>

<span class="ss">        Args:</span>

<span class="ss">            directory: the directory containing the trained policy.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="nv">@abstractmethod</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">play_implementation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">play_context</span><span class="p">:</span><span class="w"> </span><span class="n">core</span><span class="p">.</span><span class="n">PlayContext</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Agent specific implementation of playing a number of episodes with the current policy.</span>

<span class="ss">            The implementation should have the form:</span>

<span class="ss">            while True:</span>

<span class="ss">                on_play_episode_begin(env)</span>

<span class="ss">                state = env.reset()</span>

<span class="ss">                while True:</span>

<span class="ss">                    action = _trained_policy.action(state)</span>

<span class="ss">                    (state, reward, done, info) = env.step(action)</span>

<span class="ss">                    if done:</span>

<span class="ss">                        break</span>

<span class="ss">                on_play_episode_end()</span>

<span class="ss">                if play_context.play_done:</span>

<span class="ss">                    break</span>

<span class="ss">            Args:</span>

<span class="ss">                play_context: play configuration to be used</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="nv">@abstractmethod</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">save_implementation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">directory</span><span class="p">:</span><span class="w"> </span><span class="nf">str</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Agent speecific implementation of saving the weights for the actor policy.</span>

<span class="ss">        Save must only guarantee to persist the weights of the actor policy.</span>

<span class="ss">        The implementation may write multiple files with fixed filenames.</span>

<span class="ss">        Args:</span>

<span class="ss">             directory: the directory to save the policy weights to.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="nv">@abstractmethod</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_implementation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">train_context</span><span class="p">:</span><span class="w"> </span><span class="n">core</span><span class="p">.</span><span class="n">TrainContext</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Agent specific implementation of the train loop.</span>

<span class="ss">            The implementation should have the form:</span>

<span class="ss">            while True:</span>

<span class="ss">                on_iteration_begin</span>

<span class="ss">                for e in num_episodes_per_iterations</span>

<span class="ss">                    play episode and record steps (while steps_in_episode &lt; max_steps_per_episode and)</span>

<span class="ss">                train policy for num_epochs_per_iteration epochs</span>

<span class="ss">                on_iteration_end( loss )</span>

<span class="ss">                if training_done</span>

<span class="ss">                    break</span>

<span class="ss">            Args:</span>

<span class="ss">                train_context: context configuring the train loop</span>

<span class="ss">            Hints:</span>

<span class="ss">            o the subclasses training loss is passed through to BackendAgent by on_iteration_end.</span>

<span class="ss">              Thus the subclass must not add the experienced loss to the TrainContext.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro">Ancestors (in MRO)</h4>
<ul>
<li>easyagents.backends.core._BackendAgent</li>
<li>abc.ABC</li>
</ul>
<h4 id="descendants">Descendants</h4>
<ul>
<li>easyagents.backends.default.TensorforceNotActiveAgent</li>
<li>easyagents.backends.default.TfAgentsNotActiveAgent</li>
<li>easyagents.backends.default.SetTensorforceBackendAgent</li>
<li>easyagents.backends.default.NotImplementedYetAgent</li>
<li>easyagents.backends.tfagents.TfAgent</li>
</ul>
<h4 id="methods">Methods</h4>
<h5 id="load">load</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">load</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Loads a previously trained and saved actor policy from directory.</p>
<p>The loaded policy may afterwards be used by calling play().</p>
<p>Args:
    directory: the directory containing the trained policy
    callbacks: list of callbacks called during the load.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="k">load</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">directory</span><span class="p">:</span> <span class="n">str</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Loads a previously trained and saved actor policy from directory.</span>

<span class="ss">        The loaded policy may afterwards be used by calling play().</span>

<span class="ss">        Args:</span>

<span class="ss">            directory: the directory containing the trained policy</span>

<span class="ss">            callbacks: list of callbacks called during the load.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">directory</span>

        <span class="n">assert</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="k">self</span><span class="p">.</span><span class="n">load_implementation</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">_is_policy_trained</span> <span class="o">=</span> <span class="k">True</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="load_implementation">load_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">load_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">directory</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span>
</pre></div>


<p>Loads a previously trained and saved actor policy from directory.</p>
<p>The loaded policy may afterwards be used by calling play().</p>
<p>Args:
    directory: the directory containing the trained policy.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="w">    </span><span class="nv">@abstractmethod</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">load_implementation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">directory</span><span class="p">:</span><span class="w"> </span><span class="nf">str</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Loads a previously trained and saved actor policy from directory.</span>

<span class="ss">        The loaded policy may afterwards be used by calling play().</span>

<span class="ss">        Args:</span>

<span class="ss">            directory: the directory containing the trained policy.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>
</pre></div>


</details>
<h5 id="log">log</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span>
</pre></div>


<p>Logs msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">log</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">log_msg</span><span class="p">:</span> <span class="n">str</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Logs msg.&quot;&quot;&quot;</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">gym</span><span class="p">.</span><span class="n">_monitor_env</span> <span class="o">=</span> <span class="k">None</span>

        <span class="k">if</span> <span class="n">log_msg</span> <span class="k">is</span> <span class="k">None</span><span class="p">:</span>

            <span class="n">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="k">c</span> <span class="k">in</span> <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="k">c</span><span class="p">.</span><span class="n">on_log</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">,</span> <span class="n">log_msg</span><span class="o">=</span><span class="n">log_msg</span><span class="p">)</span>
</pre></div>


</details>
<h5 id="log_api">log_api</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log_api</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">api_target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>Logs a call to api_target with additional log_msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">log_api</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">api_target</span><span class="p">:</span><span class="w"> </span><span class="nf">str</span><span class="p">,</span><span class="w"> </span><span class="nl">log_msg</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">str</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Logs a call to api_target with additional log_msg.&quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">gym</span><span class="p">.</span><span class="n">_monitor_env</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">api_target</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="n">api_target</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">log_msg</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">None</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="n">log_msg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">_callbacks</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="n">c</span><span class="p">.</span><span class="n">on_api_log</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">,</span><span class="w"> </span><span class="n">api_target</span><span class="p">,</span><span class="w"> </span><span class="n">log_msg</span><span class="o">=</span><span class="n">log_msg</span><span class="p">)</span><span class="w"></span>
</pre></div>


</details>
<h5 id="on_play_episode_begin">on_play_episode_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Env</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the beginning of a new episode</p>
<p>Args:
    env: the gym environment used to play the episode.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_play_episode_begin</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="p">.</span><span class="n">core</span><span class="p">.</span><span class="n">Env</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Must be called by play_implementation at the beginning of a new episode</span>

<span class="ss">        Args:</span>

<span class="ss">            env: the gym environment used to play the episode.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">env</span><span class="p">,</span> <span class="ss">&quot;env not set.&quot;</span>

        <span class="n">assert</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">gym</span><span class="p">.</span><span class="n">core</span><span class="p">.</span><span class="n">Env</span><span class="p">),</span> <span class="ss">&quot;env not an an instance of gym.Env.&quot;</span>

        <span class="n">pc</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span>

        <span class="n">pc</span><span class="p">.</span><span class="n">gym_env</span> <span class="o">=</span> <span class="n">env</span>

        <span class="n">pc</span><span class="p">.</span><span class="n">steps_done_in_episode</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">pc</span><span class="p">.</span><span class="n">actions</span><span class="p">[</span><span class="n">pc</span><span class="p">.</span><span class="n">episodes_done</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">pc</span><span class="p">.</span><span class="n">rewards</span><span class="p">[</span><span class="n">pc</span><span class="p">.</span><span class="n">episodes_done</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">pc</span><span class="p">.</span><span class="n">sum_of_rewards</span><span class="p">[</span><span class="n">pc</span><span class="p">.</span><span class="n">episodes_done</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="k">c</span> <span class="k">in</span> <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="k">c</span><span class="p">.</span><span class="n">on_play_episode_begin</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">)</span>
</pre></div>


</details>
<h5 id="on_play_episode_end">on_play_episode_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_end</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the end of an episode</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_play_episode_end</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Must be called by play_implementation at the end of an episode&quot;&quot;&quot;</span>

        <span class="n">pc</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span>

        <span class="n">pc</span><span class="p">.</span><span class="n">episodes_done</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">pc</span><span class="p">.</span><span class="n">num_episodes</span> <span class="k">and</span> <span class="n">pc</span><span class="p">.</span><span class="n">episodes_done</span> <span class="o">&gt;=</span> <span class="n">pc</span><span class="p">.</span><span class="n">num_episodes</span><span class="p">:</span>

            <span class="n">pc</span><span class="p">.</span><span class="n">play_done</span> <span class="o">=</span> <span class="k">True</span>

        <span class="k">for</span> <span class="k">c</span> <span class="k">in</span> <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="k">c</span><span class="p">.</span><span class="n">on_play_episode_end</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_begin">on_train_iteration_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_begin</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the begining of a new iteration</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">on_train_iteration_begin</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Must be called by train_implementation at the begining of a new iteration&quot;&quot;&quot;</span>

        <span class="n">tc</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span>

        <span class="n">tc</span><span class="p">.</span><span class="n">episodes_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">tc</span><span class="p">.</span><span class="n">steps_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">tc</span><span class="p">.</span><span class="n">iterations_done_in_training</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_eval_current_policy</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">gym</span><span class="p">.</span><span class="n">_totals</span><span class="p">.</span><span class="n">episodes_done</span>

        <span class="k">for</span> <span class="k">c</span> <span class="k">in</span> <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span><span class="p">:</span>

            <span class="k">c</span><span class="p">.</span><span class="n">on_train_iteration_begin</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_end">on_train_iteration_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the end of an iteration</p>
<p>Evaluates the current policy. Use kwargs to set additional dict values in train context.
Eg for an ActorCriticTrainContext the losses may be set like this:
    on_train_iteration(loss=123,actor_loss=456,critic_loss=789)</p>
<p>Args:
    loss: loss after the training of the model in this iteration or math.nan if the loss is not available
    **kwargs: if a keyword matches a dict property of the TrainContext instance, then
                the dict[episodes_done_in_training] is set to the arg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">on_train_iteration_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">loss</span><span class="p">:</span><span class="w"> </span><span class="nc">float</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Must be called by train_implementation at the end of an iteration</span>

<span class="ss">        Evaluates the current policy. Use kwargs to set additional dict values in train context.</span>

<span class="ss">        Eg for an ActorCriticTrainContext the losses may be set like this:</span>

<span class="ss">            on_train_iteration(loss=123,actor_loss=456,critic_loss=789)</span>

<span class="ss">        Args:</span>

<span class="ss">            loss: loss after the training of the model in this iteration or math.nan if the loss is not available</span>

<span class="ss">            **kwargs: if a keyword matches a dict property of the TrainContext instance, then</span>

<span class="ss">                        the dict[episodes_done_in_training] is set to the arg.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">tc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span><span class="w"></span>

<span class="w">        </span><span class="n">totals</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">gym</span><span class="p">.</span><span class="n">_totals</span><span class="w"></span>

<span class="w">        </span><span class="n">tc</span><span class="p">.</span><span class="n">episodes_done_in_iteration</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">totals</span><span class="p">.</span><span class="n">episodes_done</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_train_total_episodes_on_iteration_begin</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">tc</span><span class="p">.</span><span class="n">episodes_done_in_training</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">tc</span><span class="p">.</span><span class="n">episodes_done_in_iteration</span><span class="w"></span>

<span class="w">        </span><span class="n">tc</span><span class="p">.</span><span class="n">loss</span><span class="o">[</span><span class="n">tc.episodes_done_in_training</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>

<span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="k">set</span><span class="w"> </span><span class="n">traincontext</span><span class="w"> </span><span class="n">dict</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="nl">kwargs</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">prop_name</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nl">kwargs</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="n">prop_instance</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">tc</span><span class="p">,</span><span class="w"> </span><span class="n">prop_name</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"></span>

<span class="w">            </span><span class="n">prop_value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kwargs</span><span class="o">[</span><span class="n">prop_name</span><span class="o">]</span><span class="w"></span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">prop_instance</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">prop_instance</span><span class="p">,</span><span class="w"> </span><span class="n">dict</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">                </span><span class="n">prop_instance</span><span class="o">[</span><span class="n">tc.episodes_done_in_training</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prop_value</span><span class="w"></span>

<span class="w">        </span><span class="n">tc</span><span class="p">.</span><span class="n">iterations_done_in_training</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">tc</span><span class="p">.</span><span class="n">num_iterations</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="n">tc</span><span class="p">.</span><span class="n">training_done</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tc</span><span class="p">.</span><span class="n">iterations_done_in_training</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">tc</span><span class="p">.</span><span class="n">num_iterations</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">_train_total_episodes_on_iteration_begin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">tc</span><span class="p">.</span><span class="n">num_iterations_between_eval</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="p">(</span><span class="n">tc</span><span class="p">.</span><span class="n">iterations_done_in_training</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">tc</span><span class="p">.</span><span class="n">num_iterations_between_eval</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">_eval_current_policy</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">_callbacks</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="n">c</span><span class="p">.</span><span class="n">on_train_iteration_end</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">)</span><span class="w"></span>
</pre></div>


</details>
<h5 id="play">play</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to play_implementation overriden by the subclass.</p>
<p>Args:
    play_context: play configuration to be used
    callbacks: list of callbacks called during play.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">play</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">play_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">PlayContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to play_implementation overriden by the subclass.</span>

<span class="ss">            Args:</span>

<span class="ss">                play_context: play configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during play.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">play_context</span><span class="p">,</span> <span class="ss">&quot;play_context not set&quot;</span>

        <span class="n">assert</span> <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="k">is</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;play_context already set in agent_context&quot;</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="n">play_context</span>

        <span class="n">old_callbacks</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">play_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">old_callbacks</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="play_implementation">play_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span>
<span class="p">)</span>
</pre></div>


<p>Agent specific implementation of playing a number of episodes with the current policy.</p>
<p>The implementation should have the form:</p>
<p>while True:
    on_play_episode_begin(env)
    state = env.reset()
    while True:
        action = _trained_policy.action(state)
        (state, reward, done, info) = env.step(action)
        if done:
            break
    on_play_episode_end()
    if play_context.play_done:
        break</p>
<p>Args:
    play_context: play configuration to be used</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="w">    </span><span class="nv">@abstractmethod</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">play_implementation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">play_context</span><span class="p">:</span><span class="w"> </span><span class="n">core</span><span class="p">.</span><span class="n">PlayContext</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Agent specific implementation of playing a number of episodes with the current policy.</span>

<span class="ss">            The implementation should have the form:</span>

<span class="ss">            while True:</span>

<span class="ss">                on_play_episode_begin(env)</span>

<span class="ss">                state = env.reset()</span>

<span class="ss">                while True:</span>

<span class="ss">                    action = _trained_policy.action(state)</span>

<span class="ss">                    (state, reward, done, info) = env.step(action)</span>

<span class="ss">                    if done:</span>

<span class="ss">                        break</span>

<span class="ss">                on_play_episode_end()</span>

<span class="ss">                if play_context.play_done:</span>

<span class="ss">                    break</span>

<span class="ss">            Args:</span>

<span class="ss">                play_context: play configuration to be used</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>
</pre></div>


</details>
<h5 id="save">save</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">save</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Saves the currently trained actor policy in directory.</p>
<p>Only the actor policy is guaranteed to be saved.
Thus after a call to load resuming training is not supported.</p>
<p>Args:
    directory: the directory to save the policy weights to. the directory must exist.
    callbacks: list of callbacks called during policy load.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">save</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">directory</span><span class="p">:</span> <span class="n">str</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Saves the currently trained actor policy in directory.</span>

<span class="ss">        Only the actor policy is guaranteed to be saved.</span>

<span class="ss">        Thus after a call to load resuming training is not supported.</span>

<span class="ss">        Args:</span>

<span class="ss">            directory: the directory to save the policy weights to. the directory must exist.</span>

<span class="ss">            callbacks: list of callbacks called during policy load.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">directory</span>

        <span class="n">assert</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>

        <span class="n">assert</span> <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">_is_policy_trained</span><span class="p">,</span> <span class="ss">&quot;No trained policy available.&quot;</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="k">self</span><span class="p">.</span><span class="n">save_implementation</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="save_implementation">save_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">save_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">directory</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span>
</pre></div>


<p>Agent speecific implementation of saving the weights for the actor policy.</p>
<p>Save must only guarantee to persist the weights of the actor policy.
The implementation may write multiple files with fixed filenames.</p>
<p>Args:
     directory: the directory to save the policy weights to.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="w">    </span><span class="nv">@abstractmethod</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">save_implementation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">directory</span><span class="p">:</span><span class="w"> </span><span class="nf">str</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Agent speecific implementation of saving the weights for the actor policy.</span>

<span class="ss">        Save must only guarantee to persist the weights of the actor policy.</span>

<span class="ss">        The implementation may write multiple files with fixed filenames.</span>

<span class="ss">        Args:</span>

<span class="ss">             directory: the directory to save the policy weights to.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>
</pre></div>


</details>
<h5 id="train">train</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to train_implementation overriden by the subclass</p>
<p>Args:
    train_context: training configuration to be used
    callbacks: list of callbacks called during the training and evaluation.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">train</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">TrainContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to train_implementation overriden by the subclass</span>

<span class="ss">            Args:</span>

<span class="ss">                train_context: training configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during the training and evaluation.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">train_context</span><span class="p">,</span> <span class="ss">&quot;train_context not set&quot;</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train_context</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="k">self</span><span class="p">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;backend_name&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;{self._backend_name}&#39;</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_set_seed</span><span class="p">()</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">_is_policy_trained</span> <span class="o">=</span> <span class="k">True</span>

            <span class="k">self</span><span class="p">.</span><span class="n">train_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="train_implementation">train_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span>
<span class="p">)</span>
</pre></div>


<p>Agent specific implementation of the train loop.</p>
<p>The implementation should have the form:</p>
<p>while True:
    on_iteration_begin
    for e in num_episodes_per_iterations
        play episode and record steps (while steps_in_episode &lt; max_steps_per_episode and)
    train policy for num_epochs_per_iteration epochs
    on_iteration_end( loss )
    if training_done
        break</p>
<p>Args:
    train_context: context configuring the train loop</p>
<p>Hints:
o the subclasses training loss is passed through to BackendAgent by on_iteration_end.
  Thus the subclass must not add the experienced loss to the TrainContext.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="w">    </span><span class="nv">@abstractmethod</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_implementation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">train_context</span><span class="p">:</span><span class="w"> </span><span class="n">core</span><span class="p">.</span><span class="n">TrainContext</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Agent specific implementation of the train loop.</span>

<span class="ss">            The implementation should have the form:</span>

<span class="ss">            while True:</span>

<span class="ss">                on_iteration_begin</span>

<span class="ss">                for e in num_episodes_per_iterations</span>

<span class="ss">                    play episode and record steps (while steps_in_episode &lt; max_steps_per_episode and)</span>

<span class="ss">                train policy for num_epochs_per_iteration epochs</span>

<span class="ss">                on_iteration_end( loss )</span>

<span class="ss">                if training_done</span>

<span class="ss">                    break</span>

<span class="ss">            Args:</span>

<span class="ss">                train_context: context configuring the train loop</span>

<span class="ss">            Hints:</span>

<span class="ss">            o the subclasses training loss is passed through to BackendAgent by on_iteration_end.</span>

<span class="ss">              Thus the subclass must not add the experienced loss to the TrainContext.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>
</pre></div>


</details>
<h3 id="backendagentfactory">BackendAgentFactory</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">BackendAgentFactory</span><span class="p">(</span>
    <span class="o">/</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>Backend agent factory defining the currently available agents (algorithms).</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="n">BackendAgentFactory</span><span class="p">(</span><span class="n">ABC</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Backend agent factory defining the currently available agents (algorithms).</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="nl">backend_name</span><span class="p">:</span><span class="w"> </span><span class="nf">str</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;abstract_BackendAgentFactory&#39;</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">create_agent</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">easyagent_type</span><span class="p">:</span><span class="w"> </span><span class="n">Type</span><span class="p">,</span><span class="w"> </span><span class="nl">model_config</span><span class="p">:</span><span class="w"> </span><span class="n">core</span><span class="p">.</span><span class="n">ModelConfig</span><span class="p">)</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">            </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">_BackendAgent</span><span class="o">]</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Creates a backend agent instance implementing the algorithm given by agent_type.</span>

<span class="ss">        Args:</span>

<span class="ss">            easyagent_type: the EasyAgent derived type for which an implementing backend instance will be created</span>

<span class="ss">            model_config: the model_config passed to the constructor of the backend instance.</span>

<span class="ss">        Returns:</span>

<span class="ss">            instance of the agent or None if not implemented by this backend.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">result</span><span class="err">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">_BackendAgent</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">        </span><span class="n">algorithms</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_algorithms</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">easyagent_type</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nl">algorithms</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">algorithms</span><span class="o">[</span><span class="n">easyagent_type</span><span class="o">]</span><span class="p">(</span><span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">result</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_algorithms</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">Type, Type[_BackendAgent</span><span class="o">]</span><span class="err">]:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Yields a mapping of EasyAgent types to the implementations provided by this backend.&quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="err">{}</span><span class="w"></span>
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro_1">Ancestors (in MRO)</h4>
<ul>
<li>abc.ABC</li>
</ul>
<h4 id="descendants_1">Descendants</h4>
<ul>
<li>easyagents.backends.default.DefaultAgentFactory</li>
<li>easyagents.backends.tfagents.TfAgentAgentFactory</li>
</ul>
<h4 id="class-variables">Class variables</h4>
<div class="codehilite"><pre><span></span><span class="n">backend_name</span>
</pre></div>


<h4 id="methods_1">Methods</h4>
<h5 id="create_agent">create_agent</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">create_agent</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">easyagent_type</span><span class="p">:</span> <span class="n">Type</span><span class="p">,</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">_BackendAgent</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span>
</pre></div>


<p>Creates a backend agent instance implementing the algorithm given by agent_type.</p>
<p>Args:
    easyagent_type: the EasyAgent derived type for which an implementing backend instance will be created
    model_config: the model_config passed to the constructor of the backend instance.</p>
<p>Returns:
    instance of the agent or None if not implemented by this backend.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">create_agent</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">easyagent_type</span><span class="p">:</span><span class="w"> </span><span class="n">Type</span><span class="p">,</span><span class="w"> </span><span class="nl">model_config</span><span class="p">:</span><span class="w"> </span><span class="n">core</span><span class="p">.</span><span class="n">ModelConfig</span><span class="p">)</span><span class="w"> </span><span class="err">\</span><span class="w"></span>

<span class="w">            </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">_BackendAgent</span><span class="o">]</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Creates a backend agent instance implementing the algorithm given by agent_type.</span>

<span class="ss">        Args:</span>

<span class="ss">            easyagent_type: the EasyAgent derived type for which an implementing backend instance will be created</span>

<span class="ss">            model_config: the model_config passed to the constructor of the backend instance.</span>

<span class="ss">        Returns:</span>

<span class="ss">            instance of the agent or None if not implemented by this backend.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">result</span><span class="err">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">_BackendAgent</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">        </span><span class="n">algorithms</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_algorithms</span><span class="p">()</span><span class="w"></span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">easyagent_type</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nl">algorithms</span><span class="p">:</span><span class="w"></span>

<span class="w">            </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">algorithms</span><span class="o">[</span><span class="n">easyagent_type</span><span class="o">]</span><span class="p">(</span><span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">result</span><span class="w"></span>
</pre></div>


</details>
<h5 id="get_algorithms">get_algorithms</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_algorithms</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Type</span><span class="p">,</span> <span class="n">Type</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">_BackendAgent</span><span class="p">]]</span>
</pre></div>


<p>Yields a mapping of EasyAgent types to the implementations provided by this backend.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">get_algorithms</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">Type, Type[_BackendAgent</span><span class="o">]</span><span class="err">]:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Yields a mapping of EasyAgent types to the implementations provided by this backend.&quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="err">{}</span><span class="w"></span>
</pre></div>


</details>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../../core/" title="Core" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Core
              </span>
            </div>
          </a>
        
        
          <a href="../tfagents/" title="Tfagents" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Tfagents
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Powered by
        <a href="http://timothycrosley.github.io/portray">portray.</a>
        You too can
        <a href="http://timothycrosley.github.io/portray">
          portray</a>
        your Python project well using automatic documentation.
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../../assets/javascripts/application.808e90bb.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../../.."}})</script>
      
    
  </body>
</html>